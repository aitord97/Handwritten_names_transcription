{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# P8 : Name Identification Using Deep Networks\n",
    "         Aitor Diaz de Otazu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal of the project is to solve the task of name transcription from handwritting images implementing a deep learning approach and using a database with a large number of images of handwritten names.\n",
    "\n",
    "This notebook describes the implementation of CNN + RNN + CTC architecture for solve this task.\n",
    "\n",
    "Link for download model and dataset: https://mega.nz/#!CLBW3CBb!WwCHdwM4kv7adoJ8IPeww_hTSm4fwLUuhEf-UIgB2Ic\n",
    "\n",
    "NOTE: This implementation uses Tensorflow 1.12 !!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/aitor/.local/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:523: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/Users/aitor/.local/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:524: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/Users/aitor/.local/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/Users/aitor/.local/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/Users/aitor/.local/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/Users/aitor/.local/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:532: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import cv2\n",
    "import pandas\n",
    "import requests\n",
    "import random\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "import urllib.request\n",
    "from time import time\n",
    "\n",
    "from skimage.color import rgb2gray"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions for preprocess the data and infer the results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#put ground truth texts into sparse tensor for ctc_loss\n",
    "def toSparse(texts):\n",
    "    indices = []\n",
    "    values = []\n",
    "    shape = [len(texts), 0] # last entry must be max(labelList[i])\n",
    "\n",
    "    # go over all texts\n",
    "    for (batchElement, text) in enumerate(texts):\n",
    "        # convert to string of label (i.e. class-ids)\n",
    "        #print(text)\n",
    "        labelStr = [charList.index(c) for c in text]\n",
    "      \n",
    "        # sparse tensor must have size of max. label-string\n",
    "        if len(labelStr) > shape[1]:\n",
    "            shape[1] = len(labelStr)\n",
    "        # put each label into sparse tensor\n",
    "        for (i, label) in enumerate(labelStr):\n",
    "            #print(label)\n",
    "            indices.append([batchElement, i])\n",
    "            values.append(label)\n",
    "\n",
    "    return (indices, values, shape)\n",
    "\n",
    "#Returns modified image with gaussian noise\n",
    "def noisyImg(image):\n",
    "    row,col= image.shape\n",
    "    mean = 0\n",
    "    var = 0.1\n",
    "    sigma = var**0.99\n",
    "    gauss = np.random.normal(mean,sigma,(row,col))\n",
    "    gauss = gauss.reshape(row,col)\n",
    "    noisy = image + gauss\n",
    "    return noisy\n",
    "\n",
    "\n",
    "#extract texts from output of CTC decoder\n",
    "def decoderOutputToText(ctcOutput, batchSize):\n",
    "    # contains string of labels for each batch element\n",
    "    encodedLabelStrs = [[] for i in range(batchSize)]\n",
    "    # word beam search: label strings terminated by blank \n",
    "    decoded=ctcOutput[0]\n",
    "\n",
    "    # go over all indices and save mapping: batch -> values\n",
    "    idxDict = { b : [] for b in range(batchSize) }\n",
    "    for (idx, idx2d) in enumerate(decoded.indices):\n",
    "        label = decoded.values[idx]\n",
    "        batchElement = idx2d[0] # index according to [b,t]\n",
    "        encodedLabelStrs[batchElement].append(label)\n",
    "\n",
    "    # map labels to chars for all batch elements\n",
    "    return [str().join([charList[c] for c in labelStr]) for labelStr in encodedLabelStrs]\n",
    "\n",
    "\n",
    "def truncateLabel(text, maxTextLen):\n",
    "    # ctc_loss can't compute loss if it cannot find a mapping between text label and input \n",
    "    # labels. Repeat letters cost double because of the blank symbol needing to be inserted.\n",
    "    # If a too-long label is provided, ctc_loss returns an infinite gradient\n",
    "    cost = 0\n",
    "    for i in range(len(text)):\n",
    "        if i != 0 and text[i] == text[i-1]:\n",
    "            cost += 2\n",
    "        else:\n",
    "            cost += 1\n",
    "        if cost > maxTextLen:\n",
    "            return text[:i]\n",
    "    return text\n",
    "    \n",
    "#Process the image for TF\n",
    "def preprocess(img, imgSize):\n",
    "\n",
    "\n",
    "    # create target image and copy sample image into it\n",
    "    (wt, ht) = imgSize\n",
    "    (h, w) = img.shape\n",
    "    fx = w / wt\n",
    "    fy = h / ht\n",
    "    f = max(fx, fy)\n",
    "    newSize = (max(min(wt, int(w / f)), 1), max(min(ht, int(h / f)), 1)) # scale according to f (result at least 1 and at most wt or ht)\n",
    "    img = cv2.resize(img, newSize,interpolation = cv2.INTER_AREA)\n",
    "    target = np.ones([ht, wt]) * 255\n",
    "    target[0:newSize[1], 0:newSize[0]] = img\n",
    "\n",
    "    # transpose for TF\n",
    "    img = cv2.transpose(target)\n",
    "\n",
    "    # normalize\n",
    "    (m, s) = cv2.meanStdDev(img)\n",
    "    m = m[0][0]\n",
    "    s = s[0][0]\n",
    "    img = img - m\n",
    "    img = img / s if s>0 else img\n",
    "    return img\n",
    "\n",
    "#Calculates accuracy based on how many characters has predicted correctly\n",
    "def accuracy(real, prediction):\n",
    "    char_num = np.array([len(x) for x in real]).sum()\n",
    "    n_correct_char = 0\n",
    "    \n",
    "    for rn,pn in zip(real,prediction):\n",
    "        for i in range(min(len(rn), len(pn))):\n",
    "            if(rn[i] == pn[i]):\n",
    "                n_correct_char +=1\n",
    "                \n",
    "    return n_correct_char/char_num\n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load the data from './HandwrittenNames-Dataset' folder\n",
    "\n",
    "X_data = np.load('HandwrittenNames-Dataset/HandwrittenNames_data.npz',allow_pickle=True)['data']\n",
    "Y_labels = np.load('HandwrittenNames-Dataset/HandwrittenNames_labels.npz',allow_pickle=True)['data']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Processing imgs and creating more train data\n",
    "x_train = []\n",
    "y_train = []\n",
    "\n",
    "for x,y in zip(X_data[:9000],Y_labels[:9000]):\n",
    "    #Resize img for TF\n",
    "    x = cv2.resize(x,(128,32),interpolation = cv2.INTER_AREA)\n",
    "    y_train.append(truncateLabel(y,32))\n",
    "    x_train.append(preprocess(x,(128,32)))\n",
    "    y_train.append(truncateLabel(y,32))\n",
    "    x_train.append(preprocess(noisyImg(x),(128,32)))\n",
    "\n",
    "x_train = np.array(x_train)\n",
    "y_train = np.array(y_train)\n",
    "\n",
    "x_test = X_data[9000:]\n",
    "y_test = Y_labels[9000:]\n",
    "\n",
    "x_test_tf = []\n",
    "\n",
    "for x in x_test :\n",
    "    #Resize img for TF\n",
    "    x = cv2.resize(x,(128,32),interpolation = cv2.INTER_AREA)\n",
    "    x_test_tf.append(preprocess(x,(128,32)))\n",
    "\n",
    "x_test_tf = np.array(x_test_tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of element for train: 18000\n",
      "Number of element for test: 982\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of element for train:\",x_train.shape[0])\n",
    "\n",
    "print(\"Number of element for test:\",x_test.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def next_batch(prev_batch, batch_size):\n",
    "    return np.array(x_train[prev_batch:prev_batch + batch_size]), y_train[prev_batch:prev_batch + batch_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.title(\"Image for the model\")\n",
    "plt.imshow(x_train[0], cmap=plt.cm.gray)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "plt.title(\"Original image\")\n",
    "plt.imshow(X_data[0], cmap=plt.cm.gray)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def predict(imgs):\n",
    "    \n",
    "    numBatchElements = len(imgs)\n",
    "    evalList = [decoder] + ([])\n",
    "    feedDict = {Input : imgs, seqLen : [32] * numBatchElements}\n",
    "    evalRes = sess.run(evalList, feedDict)\n",
    "\n",
    "    decoded = evalRes[0][0]\n",
    "    #print(decoded)\n",
    "    texts = decoderOutputToText(decoded, numBatchElements)\n",
    "    \n",
    "    return (texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(?, 128, 32, 1)\n",
      "(?, 32, 1, 256)\n",
      "Tensor(\"Squeeze:0\", shape=(?, 32, 256), dtype=float32)\n",
      "Tensor(\"transpose:0\", shape=(32, ?, 29), dtype=float32)\n",
      "([<tensorflow.python.framework.sparse_tensor.SparseTensor object at 0x1cb4fecfd0>], <tf.Tensor 'CTCBeamSearchDecoder:3' shape=(?, 1) dtype=float32>)\n"
     ]
    }
   ],
   "source": [
    "# Model parameters\n",
    "\n",
    "\n",
    "\n",
    "tf.reset_default_graph()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "batchSize = 50\n",
    "imgSize = (128, 32)\n",
    "maxTextLen = 32\n",
    "kernel_vals = [5, 5, 3, 3, 3]\n",
    "feature_vals = [1, 32, 64, 64, 128, 256]\n",
    "stride_vals = pool_vals = [(2,2), (2,2), (1,2), (1,2), (1,2)]\n",
    "\n",
    "num_rnn_hiden = 256\n",
    "\n",
    "charList = \"ABCDEFGHIJKLMNOPQRSTUVWXYZ- \"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#Input layer\n",
    "Input = tf.placeholder(tf.float32, shape=(None, imgSize[0], imgSize[1]))\n",
    "\n",
    "#CNN\n",
    "\n",
    "cnnIn4d = tf.expand_dims(input=Input, axis=3)\n",
    "print(cnnIn4d.shape)\n",
    "\n",
    "kernel0 = tf.Variable(tf.truncated_normal([kernel_vals[0], kernel_vals[0],feature_vals[0], feature_vals[1]], stddev=0.1))\n",
    "kernel1 = tf.Variable(tf.truncated_normal([kernel_vals[1], kernel_vals[1],feature_vals[1], feature_vals[2]], stddev=0.1))\n",
    "kernel2 = tf.Variable(tf.truncated_normal([kernel_vals[2], kernel_vals[2],feature_vals[2], feature_vals[3]], stddev=0.1))\n",
    "kernel3 = tf.Variable(tf.truncated_normal([kernel_vals[3], kernel_vals[3],feature_vals[3], feature_vals[4]], stddev=0.1))\n",
    "kernel4 = tf.Variable(tf.truncated_normal([kernel_vals[4], kernel_vals[4],feature_vals[4], feature_vals[5]], stddev=0.1))\n",
    "\n",
    "#First CNN layer\n",
    "conv0 = tf.nn.conv2d(cnnIn4d, kernel0, padding='SAME',  strides=(1,1,1,1))\n",
    "relu0 = tf.nn.relu(conv0)\n",
    "pool0 = tf.nn.max_pool(relu0, (1, pool_vals[0][0], pool_vals[0][1], 1), \n",
    "                       (1, stride_vals[0][0], stride_vals[0][1], 1), 'VALID')\n",
    "\n",
    "#Second CNN layer\n",
    "conv1 = tf.nn.conv2d(pool0, kernel1, padding='SAME',  strides=(1,1,1,1))\n",
    "relu1 = tf.nn.relu(conv1)\n",
    "pool1 = tf.nn.max_pool(relu1, (1, pool_vals[1][0], pool_vals[1][1], 1), \n",
    "                       (1, stride_vals[1][0], stride_vals[1][1], 1), 'VALID')\n",
    "\n",
    "#Third CNN layer\n",
    "conv2 = tf.nn.conv2d(pool1, kernel2, padding='SAME',  strides=(1,1,1,1))\n",
    "relu2 = tf.nn.relu(conv2)\n",
    "pool2 = tf.nn.max_pool(relu2, (1, pool_vals[2][0], pool_vals[2][1], 1), \n",
    "                       (1, stride_vals[2][0], stride_vals[2][1], 1), 'VALID')\n",
    "\n",
    "#Fourth CNN layer\n",
    "conv3 = tf.nn.conv2d(pool2, kernel3, padding='SAME',  strides=(1,1,1,1))\n",
    "relu3 = tf.nn.relu(conv3)\n",
    "pool3 = tf.nn.max_pool(relu3, (1, pool_vals[3][0], pool_vals[3][1], 1), \n",
    "                       (1, stride_vals[3][0], stride_vals[3][1], 1), 'VALID')\n",
    "\n",
    "#Fifth CNN layer\n",
    "conv4 = tf.nn.conv2d(pool3, kernel4, padding='SAME',  strides=(1,1,1,1))\n",
    "relu4 = tf.nn.relu(conv4)\n",
    "pool4 = tf.nn.max_pool(relu4, (1, pool_vals[4][0], pool_vals[4][1], 1), \n",
    "                       (1, stride_vals[4][0], stride_vals[4][1], 1), 'VALID')\n",
    "print(pool4.shape)\n",
    "\n",
    "\n",
    "#RNN\n",
    "rnnIn3d = tf.squeeze(pool4, axis=[2])\n",
    "\n",
    "cells = [tf.contrib.rnn.LSTMCell(num_units=num_rnn_hiden, state_is_tuple=True) for _ in range(2)] # 2 layers\n",
    "\n",
    "stacked = tf.contrib.rnn.MultiRNNCell(cells, state_is_tuple=True) # stack basic cells\n",
    "\n",
    "# bidirectional RNN\n",
    "\n",
    "((fw, bw), _) = tf.nn.bidirectional_dynamic_rnn(cell_fw=stacked, \n",
    "                                               cell_bw=stacked, inputs=rnnIn3d, dtype=rnnIn3d.dtype)\n",
    "concat = tf.expand_dims(tf.concat([fw, bw], 2), 2)\n",
    "\n",
    "# project output to chars (including blank): BxTx1x2H -> BxTx1xC -> BxTxC\n",
    "kernel = tf.Variable(tf.truncated_normal([1, 1, num_rnn_hiden * 2, len(charList) + 1], stddev=0.1))\n",
    "\n",
    "rnnOut3d = tf.squeeze(tf.nn.atrous_conv2d(value=concat, filters=kernel, rate=1, padding='SAME'), axis=[2])\n",
    "print(rnnIn3d)\n",
    "\n",
    "#BTC\n",
    "ctcIn3dTBC = tf.transpose(rnnOut3d, [1, 0, 2])\n",
    "print(ctcIn3dTBC)\n",
    "# ground truth text as sparse tensor\n",
    "gtTexts = tf.SparseTensor(tf.placeholder(tf.int64, shape=[None, 2]) , tf.placeholder(tf.int32, [None]), tf.placeholder(tf.int64, [2]))\n",
    "\n",
    "# calc loss for batch\n",
    "seqLen = tf.placeholder(tf.int32, [None])\n",
    "loss = tf.reduce_mean(tf.nn.ctc_loss(labels=gtTexts, inputs=ctcIn3dTBC, sequence_length=seqLen, ctc_merge_repeated=True))\n",
    "\n",
    "# calc loss for each element to compute label probability\n",
    "savedCtcInput = tf.placeholder(tf.float32, shape=[maxTextLen, None, len(charList) + 1])\n",
    "lossPerElement = tf.nn.ctc_loss(labels=gtTexts, inputs=savedCtcInput, sequence_length=seqLen, ctc_merge_repeated=True)\n",
    "\n",
    "decoder = tf.nn.ctc_beam_search_decoder(inputs=ctcIn3dTBC, sequence_length= seqLen , beam_width=50, merge_repeated=False)\n",
    "print(decoder)\n",
    "\n",
    "#Optimizer\n",
    "learningRate = tf.placeholder(tf.float32, shape=[])\n",
    "optimizer = tf.train.RMSPropOptimizer(learningRate).minimize(loss)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./checkpoints/HTRModel\n"
     ]
    }
   ],
   "source": [
    "#LOAD TRAINED MODEL\n",
    "\n",
    "\n",
    "sess = tf.Session()\n",
    "latestSnapshot = tf.train.latest_checkpoint('./checkpoints')\n",
    "saver.restore(sess, latestSnapshot)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------ Training ------------------\n",
      "Epoch:  0 Batch:  0 loss: 83.3006\n",
      "Epoch:  0 Batch:  10 loss: 30.902311\n",
      "Epoch:  0 Batch:  20 loss: 25.08834\n",
      "Epoch:  0 Batch:  30 loss: 22.0158\n",
      "Epoch:  0 Batch:  40 loss: 19.246923\n",
      "Epoch:  0 Batch:  50 loss: 19.246096\n",
      "Epoch:  0 Batch:  60 loss: 18.776695\n",
      "Epoch:  0 Batch:  70 loss: 18.080978\n",
      "Epoch:  0 Batch:  80 loss: 18.931654\n",
      "Epoch:  0 Batch:  90 loss: 20.172142\n",
      "Epoch:  0 Batch:  100 loss: 18.136076\n",
      "Epoch:  0 Batch:  110 loss: 16.271587\n",
      "Epoch:  0 Batch:  120 loss: 19.406858\n",
      "Epoch:  0 Batch:  130 loss: 17.150263\n",
      "Epoch:  0 Batch:  140 loss: 16.364552\n",
      "Epoch:  0 Batch:  150 loss: 18.854856\n",
      "Epoch:  0 Batch:  160 loss: 17.720566\n",
      "Epoch:  0 Batch:  170 loss: 17.235943\n",
      "Epoch:  0 Batch:  180 loss: 16.117247\n",
      "Epoch:  0 Batch:  190 loss: 16.181835\n",
      "Epoch:  0 Batch:  200 loss: 16.087822\n",
      "Epoch:  0 Batch:  210 loss: 18.491447\n",
      "Epoch:  0 Batch:  220 loss: 16.679052\n",
      "Epoch:  0 Batch:  230 loss: 15.517141\n",
      "Epoch:  0 Batch:  240 loss: 16.159992\n",
      "Epoch:  0 Batch:  250 loss: 18.805075\n",
      "Epoch:  0 Batch:  260 loss: 17.790882\n",
      "Epoch:  0 Batch:  270 loss: 15.460302\n",
      "Epoch:  0 Batch:  280 loss: 14.4259\n",
      "Epoch:  0 Batch:  290 loss: 15.505976\n",
      "Epoch:  0 Batch:  300 loss: 16.68822\n",
      "Epoch:  0 Batch:  310 loss: 18.540369\n",
      "Epoch:  0 Batch:  320 loss: 16.594164\n",
      "Epoch:  0 Batch:  330 loss: 16.911406\n",
      "Epoch:  0 Batch:  340 loss: 17.185562\n",
      "Epoch:  0 Batch:  350 loss: 16.284264\n",
      "------------------ Epoch finished ------------------\n",
      "Saving epoch 0 ...\n",
      "Checkpoint saved successfully! Time: 0 s\n",
      "Epoch:  1 Batch:  0 loss: 17.0438\n",
      "Epoch:  1 Batch:  10 loss: 15.904236\n",
      "Epoch:  1 Batch:  20 loss: 17.417797\n",
      "Epoch:  1 Batch:  30 loss: 16.470291\n",
      "Epoch:  1 Batch:  40 loss: 14.482074\n",
      "Epoch:  1 Batch:  50 loss: 16.569637\n",
      "Epoch:  1 Batch:  60 loss: 15.644698\n",
      "Epoch:  1 Batch:  70 loss: 15.091864\n",
      "Epoch:  1 Batch:  80 loss: 16.940245\n",
      "Epoch:  1 Batch:  90 loss: 16.306011\n",
      "Epoch:  1 Batch:  100 loss: 15.317788\n",
      "Epoch:  1 Batch:  110 loss: 14.020241\n",
      "Epoch:  1 Batch:  120 loss: 17.30227\n",
      "Epoch:  1 Batch:  130 loss: 14.596287\n",
      "Epoch:  1 Batch:  140 loss: 14.064227\n",
      "Epoch:  1 Batch:  150 loss: 17.09002\n",
      "Epoch:  1 Batch:  160 loss: 15.162101\n",
      "Epoch:  1 Batch:  170 loss: 14.822249\n",
      "Epoch:  1 Batch:  180 loss: 14.123614\n",
      "Epoch:  1 Batch:  190 loss: 14.275907\n",
      "Epoch:  1 Batch:  200 loss: 14.09501\n",
      "Epoch:  1 Batch:  210 loss: 15.510332\n",
      "Epoch:  1 Batch:  220 loss: 14.676366\n",
      "Epoch:  1 Batch:  230 loss: 13.0496645\n",
      "Epoch:  1 Batch:  240 loss: 14.409257\n",
      "Epoch:  1 Batch:  250 loss: 17.154243\n",
      "Epoch:  1 Batch:  260 loss: 15.368425\n",
      "Epoch:  1 Batch:  270 loss: 13.168497\n",
      "Epoch:  1 Batch:  280 loss: 12.981503\n",
      "Epoch:  1 Batch:  290 loss: 13.79016\n",
      "Epoch:  1 Batch:  300 loss: 14.663501\n",
      "Epoch:  1 Batch:  310 loss: 17.59397\n",
      "Epoch:  1 Batch:  320 loss: 14.443238\n",
      "Epoch:  1 Batch:  330 loss: 14.731851\n",
      "Epoch:  1 Batch:  340 loss: 15.188624\n",
      "Epoch:  1 Batch:  350 loss: 13.975359\n",
      "------------------ Epoch finished ------------------\n",
      "Saving epoch 1 ...\n",
      "Checkpoint saved successfully! Time: 0 s\n",
      "Epoch:  2 Batch:  0 loss: 14.947914\n",
      "Epoch:  2 Batch:  10 loss: 13.793443\n",
      "Epoch:  2 Batch:  20 loss: 14.975877\n",
      "Epoch:  2 Batch:  30 loss: 14.355175\n",
      "Epoch:  2 Batch:  40 loss: 12.859558\n",
      "Epoch:  2 Batch:  50 loss: 15.224902\n",
      "Epoch:  2 Batch:  60 loss: 14.18067\n",
      "Epoch:  2 Batch:  70 loss: 13.023396\n",
      "Epoch:  2 Batch:  80 loss: 14.844509\n",
      "Epoch:  2 Batch:  90 loss: 14.346531\n",
      "Epoch:  2 Batch:  100 loss: 13.332799\n",
      "Epoch:  2 Batch:  110 loss: 12.463061\n",
      "Epoch:  2 Batch:  120 loss: 15.632346\n",
      "Epoch:  2 Batch:  130 loss: 12.5592785\n",
      "Epoch:  2 Batch:  140 loss: 12.28676\n",
      "Epoch:  2 Batch:  150 loss: 15.75275\n",
      "Epoch:  2 Batch:  160 loss: 12.459097\n",
      "Epoch:  2 Batch:  170 loss: 12.733228\n",
      "Epoch:  2 Batch:  180 loss: 13.025749\n",
      "Epoch:  2 Batch:  190 loss: 12.648149\n",
      "Epoch:  2 Batch:  200 loss: 11.960705\n",
      "Epoch:  2 Batch:  210 loss: 12.718684\n",
      "Epoch:  2 Batch:  220 loss: 12.735965\n",
      "Epoch:  2 Batch:  230 loss: 11.194032\n",
      "Epoch:  2 Batch:  240 loss: 12.699441\n",
      "Epoch:  2 Batch:  250 loss: 15.502236\n",
      "Epoch:  2 Batch:  260 loss: 13.448451\n",
      "Epoch:  2 Batch:  270 loss: 11.225376\n",
      "Epoch:  2 Batch:  280 loss: 11.493229\n",
      "Epoch:  2 Batch:  290 loss: 12.331644\n",
      "Epoch:  2 Batch:  300 loss: 12.728796\n",
      "Epoch:  2 Batch:  310 loss: 15.300039\n",
      "Epoch:  2 Batch:  320 loss: 12.478484\n",
      "Epoch:  2 Batch:  330 loss: 13.185085\n",
      "Epoch:  2 Batch:  340 loss: 13.167808\n",
      "Epoch:  2 Batch:  350 loss: 12.062969\n",
      "------------------ Epoch finished ------------------\n",
      "Saving epoch 2 ...\n",
      "Checkpoint saved successfully! Time: 0 s\n",
      "Epoch:  3 Batch:  0 loss: 13.108921\n",
      "Epoch:  3 Batch:  10 loss: 12.005421\n",
      "Epoch:  3 Batch:  20 loss: 12.836944\n",
      "Epoch:  3 Batch:  30 loss: 12.829315\n",
      "Epoch:  3 Batch:  40 loss: 11.722983\n",
      "Epoch:  3 Batch:  50 loss: 13.127595\n",
      "Epoch:  3 Batch:  60 loss: 13.157029\n",
      "Epoch:  3 Batch:  70 loss: 11.173166\n",
      "Epoch:  3 Batch:  80 loss: 13.120218\n",
      "Epoch:  3 Batch:  90 loss: 12.382574\n",
      "Epoch:  3 Batch:  100 loss: 12.044792\n",
      "Epoch:  3 Batch:  110 loss: 10.936841\n",
      "Epoch:  3 Batch:  120 loss: 13.60804\n",
      "Epoch:  3 Batch:  130 loss: 10.9384575\n",
      "Epoch:  3 Batch:  140 loss: 10.823526\n",
      "Epoch:  3 Batch:  150 loss: 14.395819\n",
      "Epoch:  3 Batch:  160 loss: 10.686677\n",
      "Epoch:  3 Batch:  170 loss: 11.158098\n",
      "Epoch:  3 Batch:  180 loss: 11.73131\n",
      "Epoch:  3 Batch:  190 loss: 11.307233\n",
      "Epoch:  3 Batch:  200 loss: 10.557007\n",
      "Epoch:  3 Batch:  210 loss: 10.407815\n",
      "Epoch:  3 Batch:  220 loss: 11.092058\n",
      "Epoch:  3 Batch:  230 loss: 9.9960165\n",
      "Epoch:  3 Batch:  240 loss: 10.897051\n",
      "Epoch:  3 Batch:  250 loss: 13.76226\n",
      "Epoch:  3 Batch:  260 loss: 11.21333\n",
      "Epoch:  3 Batch:  270 loss: 9.7057295\n",
      "Epoch:  3 Batch:  280 loss: 9.7416\n",
      "Epoch:  3 Batch:  290 loss: 10.832249\n",
      "Epoch:  3 Batch:  300 loss: 10.624607\n",
      "Epoch:  3 Batch:  310 loss: 13.747387\n",
      "Epoch:  3 Batch:  320 loss: 10.36534\n",
      "Epoch:  3 Batch:  330 loss: 11.37598\n",
      "Epoch:  3 Batch:  340 loss: 11.192526\n",
      "Epoch:  3 Batch:  350 loss: 10.513994\n",
      "------------------ Epoch finished ------------------\n",
      "Saving epoch 3 ...\n",
      "Checkpoint saved successfully! Time: 0 s\n",
      "Epoch:  4 Batch:  0 loss: 11.574652\n",
      "Epoch:  4 Batch:  10 loss: 10.422125\n",
      "Epoch:  4 Batch:  20 loss: 10.903572\n",
      "Epoch:  4 Batch:  30 loss: 11.082275\n",
      "Epoch:  4 Batch:  40 loss: 9.951651\n",
      "Epoch:  4 Batch:  50 loss: 11.535293\n",
      "Epoch:  4 Batch:  60 loss: 11.794302\n",
      "Epoch:  4 Batch:  70 loss: 9.708683\n",
      "Epoch:  4 Batch:  80 loss: 11.297796\n",
      "Epoch:  4 Batch:  90 loss: 10.525879\n",
      "Epoch:  4 Batch:  100 loss: 10.654773\n",
      "Epoch:  4 Batch:  110 loss: 9.006186\n",
      "Epoch:  4 Batch:  120 loss: 11.833321\n",
      "Epoch:  4 Batch:  130 loss: 9.55087\n",
      "Epoch:  4 Batch:  140 loss: 9.449172\n",
      "Epoch:  4 Batch:  150 loss: 12.874297\n",
      "Epoch:  4 Batch:  160 loss: 9.18357\n",
      "Epoch:  4 Batch:  170 loss: 9.905491\n",
      "Epoch:  4 Batch:  180 loss: 10.153443\n",
      "Epoch:  4 Batch:  190 loss: 9.595024\n",
      "Epoch:  4 Batch:  200 loss: 9.602955\n",
      "Epoch:  4 Batch:  210 loss: 8.103935\n",
      "Epoch:  4 Batch:  220 loss: 9.461791\n",
      "Epoch:  4 Batch:  230 loss: 8.439264\n",
      "Epoch:  4 Batch:  240 loss: 8.759169\n",
      "Epoch:  4 Batch:  250 loss: 12.494786\n",
      "Epoch:  4 Batch:  260 loss: 9.237851\n",
      "Epoch:  4 Batch:  270 loss: 8.347828\n",
      "Epoch:  4 Batch:  280 loss: 8.339475\n",
      "Epoch:  4 Batch:  290 loss: 9.6538105\n",
      "Epoch:  4 Batch:  300 loss: 8.736279\n",
      "Epoch:  4 Batch:  310 loss: 12.431516\n",
      "Epoch:  4 Batch:  320 loss: 8.660454\n",
      "Epoch:  4 Batch:  330 loss: 10.002774\n",
      "Epoch:  4 Batch:  340 loss: 9.597489\n",
      "Epoch:  4 Batch:  350 loss: 8.875864\n",
      "------------------ Epoch finished ------------------\n",
      "Saving epoch 4 ...\n",
      "Checkpoint saved successfully! Time: 0 s\n",
      "Epoch:  5 Batch:  0 loss: 10.267273\n",
      "Epoch:  5 Batch:  10 loss: 9.005719\n",
      "Epoch:  5 Batch:  20 loss: 9.436802\n",
      "Epoch:  5 Batch:  30 loss: 9.245237\n",
      "Epoch:  5 Batch:  40 loss: 8.98593\n",
      "Epoch:  5 Batch:  50 loss: 9.883638\n",
      "Epoch:  5 Batch:  60 loss: 10.485542\n",
      "Epoch:  5 Batch:  70 loss: 8.409342\n",
      "Epoch:  5 Batch:  80 loss: 9.786734\n",
      "Epoch:  5 Batch:  90 loss: 8.792878\n",
      "Epoch:  5 Batch:  100 loss: 9.006126\n",
      "Epoch:  5 Batch:  110 loss: 7.7489257\n",
      "Epoch:  5 Batch:  120 loss: 10.388993\n",
      "Epoch:  5 Batch:  130 loss: 8.091479\n",
      "Epoch:  5 Batch:  140 loss: 8.112208\n",
      "Epoch:  5 Batch:  150 loss: 11.474587\n",
      "Epoch:  5 Batch:  160 loss: 7.9931087\n",
      "Epoch:  5 Batch:  170 loss: 8.574765\n",
      "Epoch:  5 Batch:  180 loss: 8.544575\n",
      "Epoch:  5 Batch:  190 loss: 8.375162\n",
      "Epoch:  5 Batch:  200 loss: 8.252654\n",
      "Epoch:  5 Batch:  210 loss: 6.3076615\n",
      "Epoch:  5 Batch:  220 loss: 8.086398\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  5 Batch:  230 loss: 6.988201\n",
      "Epoch:  5 Batch:  240 loss: 6.97894\n",
      "Epoch:  5 Batch:  250 loss: 11.546445\n",
      "Epoch:  5 Batch:  260 loss: 7.479911\n",
      "Epoch:  5 Batch:  270 loss: 7.0377803\n",
      "Epoch:  5 Batch:  280 loss: 7.0529523\n",
      "Epoch:  5 Batch:  290 loss: 8.447876\n",
      "Epoch:  5 Batch:  300 loss: 7.0428815\n",
      "Epoch:  5 Batch:  310 loss: 11.328662\n",
      "Epoch:  5 Batch:  320 loss: 7.0601764\n",
      "Epoch:  5 Batch:  330 loss: 8.718971\n",
      "Epoch:  5 Batch:  340 loss: 7.981792\n",
      "Epoch:  5 Batch:  350 loss: 7.1818876\n",
      "------------------ Epoch finished ------------------\n",
      "Saving epoch 5 ...\n",
      "Checkpoint saved successfully! Time: 0 s\n",
      "Epoch:  6 Batch:  0 loss: 8.503502\n",
      "Epoch:  6 Batch:  10 loss: 7.439161\n",
      "Epoch:  6 Batch:  20 loss: 7.7430634\n",
      "Epoch:  6 Batch:  30 loss: 7.428199\n",
      "Epoch:  6 Batch:  40 loss: 7.5311723\n",
      "Epoch:  6 Batch:  50 loss: 8.138377\n",
      "Epoch:  6 Batch:  60 loss: 8.878947\n",
      "Epoch:  6 Batch:  70 loss: 6.8156223\n",
      "Epoch:  6 Batch:  80 loss: 7.9827495\n",
      "Epoch:  6 Batch:  90 loss: 6.8453045\n",
      "Epoch:  6 Batch:  100 loss: 7.3356175\n",
      "Epoch:  6 Batch:  110 loss: 6.1303186\n",
      "Epoch:  6 Batch:  120 loss: 8.474284\n",
      "Epoch:  6 Batch:  130 loss: 6.4778504\n",
      "Epoch:  6 Batch:  140 loss: 6.527232\n",
      "Epoch:  6 Batch:  150 loss: 9.7767315\n",
      "Epoch:  6 Batch:  160 loss: 6.384611\n",
      "Epoch:  6 Batch:  170 loss: 7.6335683\n",
      "Epoch:  6 Batch:  180 loss: 6.938063\n",
      "Epoch:  6 Batch:  190 loss: 6.8625546\n",
      "Epoch:  6 Batch:  200 loss: 6.279552\n",
      "Epoch:  6 Batch:  210 loss: 4.4208364\n",
      "Epoch:  6 Batch:  220 loss: 6.6353545\n",
      "Epoch:  6 Batch:  230 loss: 5.559157\n",
      "Epoch:  6 Batch:  240 loss: 5.702436\n",
      "Epoch:  6 Batch:  250 loss: 10.428101\n",
      "Epoch:  6 Batch:  260 loss: 5.70896\n",
      "Epoch:  6 Batch:  270 loss: 5.799684\n",
      "Epoch:  6 Batch:  280 loss: 5.805969\n",
      "Epoch:  6 Batch:  290 loss: 6.935859\n",
      "Epoch:  6 Batch:  300 loss: 5.5364013\n",
      "Epoch:  6 Batch:  310 loss: 9.974438\n",
      "Epoch:  6 Batch:  320 loss: 5.744453\n",
      "Epoch:  6 Batch:  330 loss: 7.7443995\n",
      "Epoch:  6 Batch:  340 loss: 6.411787\n",
      "Epoch:  6 Batch:  350 loss: 5.6666136\n",
      "------------------ Epoch finished ------------------\n",
      "Saving epoch 6 ...\n",
      "Checkpoint saved successfully! Time: 0 s\n",
      "Epoch:  7 Batch:  0 loss: 7.1850886\n",
      "Epoch:  7 Batch:  10 loss: 6.080519\n",
      "Epoch:  7 Batch:  20 loss: 6.1589656\n",
      "Epoch:  7 Batch:  30 loss: 6.0220137\n",
      "Epoch:  7 Batch:  40 loss: 6.193483\n",
      "Epoch:  7 Batch:  50 loss: 6.6528916\n",
      "Epoch:  7 Batch:  60 loss: 8.016819\n",
      "Epoch:  7 Batch:  70 loss: 5.8572817\n",
      "Epoch:  7 Batch:  80 loss: 6.95379\n",
      "Epoch:  7 Batch:  90 loss: 5.7908397\n",
      "Epoch:  7 Batch:  100 loss: 6.462583\n",
      "Epoch:  7 Batch:  110 loss: 5.2761464\n",
      "Epoch:  7 Batch:  120 loss: 7.2313237\n",
      "Epoch:  7 Batch:  130 loss: 5.213353\n",
      "Epoch:  7 Batch:  140 loss: 5.471264\n",
      "Epoch:  7 Batch:  150 loss: 8.657635\n",
      "Epoch:  7 Batch:  160 loss: 5.6351433\n",
      "Epoch:  7 Batch:  170 loss: 6.9699445\n",
      "Epoch:  7 Batch:  180 loss: 5.8523784\n",
      "Epoch:  7 Batch:  190 loss: 5.869644\n",
      "Epoch:  7 Batch:  200 loss: 5.396946\n",
      "Epoch:  7 Batch:  210 loss: 3.241281\n",
      "Epoch:  7 Batch:  220 loss: 5.5505543\n",
      "Epoch:  7 Batch:  230 loss: 4.541734\n",
      "Epoch:  7 Batch:  240 loss: 4.7250123\n",
      "Epoch:  7 Batch:  250 loss: 9.599654\n",
      "Epoch:  7 Batch:  260 loss: 4.873444\n",
      "Epoch:  7 Batch:  270 loss: 5.017713\n",
      "Epoch:  7 Batch:  280 loss: 5.2127256\n",
      "Epoch:  7 Batch:  290 loss: 5.9858384\n",
      "Epoch:  7 Batch:  300 loss: 4.482669\n",
      "Epoch:  7 Batch:  310 loss: 9.312984\n",
      "Epoch:  7 Batch:  320 loss: 4.567774\n",
      "Epoch:  7 Batch:  330 loss: 6.9913807\n",
      "Epoch:  7 Batch:  340 loss: 5.4411626\n",
      "Epoch:  7 Batch:  350 loss: 4.7493095\n",
      "------------------ Epoch finished ------------------\n",
      "Saving epoch 7 ...\n",
      "Checkpoint saved successfully! Time: 0 s\n",
      "Epoch:  8 Batch:  0 loss: 6.261535\n",
      "Epoch:  8 Batch:  10 loss: 5.239281\n",
      "Epoch:  8 Batch:  20 loss: 5.306898\n",
      "Epoch:  8 Batch:  30 loss: 5.0937104\n",
      "Epoch:  8 Batch:  40 loss: 5.5666714\n",
      "Epoch:  8 Batch:  50 loss: 5.9333143\n",
      "Epoch:  8 Batch:  60 loss: 7.5266576\n",
      "Epoch:  8 Batch:  70 loss: 5.108591\n",
      "Epoch:  8 Batch:  80 loss: 6.0621266\n",
      "Epoch:  8 Batch:  90 loss: 5.193749\n",
      "Epoch:  8 Batch:  100 loss: 5.544424\n",
      "Epoch:  8 Batch:  110 loss: 4.8204355\n",
      "Epoch:  8 Batch:  120 loss: 6.537175\n",
      "Epoch:  8 Batch:  130 loss: 4.339643\n",
      "Epoch:  8 Batch:  140 loss: 4.9438915\n",
      "Epoch:  8 Batch:  150 loss: 7.7665424\n",
      "Epoch:  8 Batch:  160 loss: 4.773793\n",
      "Epoch:  8 Batch:  170 loss: 6.1200533\n",
      "Epoch:  8 Batch:  180 loss: 5.1309223\n",
      "Epoch:  8 Batch:  190 loss: 5.0276027\n",
      "Epoch:  8 Batch:  200 loss: 4.623008\n",
      "Epoch:  8 Batch:  210 loss: 2.5092683\n",
      "Epoch:  8 Batch:  220 loss: 4.71337\n",
      "Epoch:  8 Batch:  230 loss: 3.9354877\n",
      "Epoch:  8 Batch:  240 loss: 4.2797403\n",
      "Epoch:  8 Batch:  250 loss: 9.003008\n",
      "Epoch:  8 Batch:  260 loss: 4.1012964\n",
      "Epoch:  8 Batch:  270 loss: 4.362667\n",
      "Epoch:  8 Batch:  280 loss: 4.704151\n",
      "Epoch:  8 Batch:  290 loss: 5.1749406\n",
      "Epoch:  8 Batch:  300 loss: 3.875856\n",
      "Epoch:  8 Batch:  310 loss: 8.638764\n",
      "Epoch:  8 Batch:  320 loss: 3.9516227\n",
      "Epoch:  8 Batch:  330 loss: 6.443279\n",
      "Epoch:  8 Batch:  340 loss: 4.5966854\n",
      "Epoch:  8 Batch:  350 loss: 4.1488338\n",
      "------------------ Epoch finished ------------------\n",
      "Saving epoch 8 ...\n",
      "Checkpoint saved successfully! Time: 0 s\n",
      "Epoch:  9 Batch:  0 loss: 5.621528\n",
      "Epoch:  9 Batch:  10 loss: 4.580893\n",
      "Epoch:  9 Batch:  20 loss: 4.56202\n",
      "Epoch:  9 Batch:  30 loss: 4.447929\n",
      "Epoch:  9 Batch:  40 loss: 5.01699\n",
      "Epoch:  9 Batch:  50 loss: 5.163073\n",
      "Epoch:  9 Batch:  60 loss: 6.812387\n",
      "Epoch:  9 Batch:  70 loss: 4.349631\n",
      "Epoch:  9 Batch:  80 loss: 5.363606\n",
      "Epoch:  9 Batch:  90 loss: 4.7644596\n",
      "Epoch:  9 Batch:  100 loss: 5.0856357\n",
      "Epoch:  9 Batch:  110 loss: 4.3222485\n",
      "Epoch:  9 Batch:  120 loss: 5.7347164\n",
      "Epoch:  9 Batch:  130 loss: 3.686741\n",
      "Epoch:  9 Batch:  140 loss: 4.436763\n",
      "Epoch:  9 Batch:  150 loss: 6.888657\n",
      "Epoch:  9 Batch:  160 loss: 4.205522\n",
      "Epoch:  9 Batch:  170 loss: 5.7450714\n",
      "Epoch:  9 Batch:  180 loss: 4.7497115\n",
      "Epoch:  9 Batch:  190 loss: 4.32189\n",
      "Epoch:  9 Batch:  200 loss: 4.1282015\n",
      "Epoch:  9 Batch:  210 loss: 1.9927155\n",
      "Epoch:  9 Batch:  220 loss: 3.9713428\n",
      "Epoch:  9 Batch:  230 loss: 3.3072271\n",
      "Epoch:  9 Batch:  240 loss: 3.5735614\n",
      "Epoch:  9 Batch:  250 loss: 8.216976\n",
      "Epoch:  9 Batch:  260 loss: 3.5561411\n",
      "Epoch:  9 Batch:  270 loss: 3.7954428\n",
      "Epoch:  9 Batch:  280 loss: 4.3208523\n",
      "Epoch:  9 Batch:  290 loss: 4.7068105\n",
      "Epoch:  9 Batch:  300 loss: 3.1879666\n",
      "Epoch:  9 Batch:  310 loss: 8.099713\n",
      "Epoch:  9 Batch:  320 loss: 3.4102035\n",
      "Epoch:  9 Batch:  330 loss: 5.924314\n",
      "Epoch:  9 Batch:  340 loss: 3.828964\n",
      "Epoch:  9 Batch:  350 loss: 3.6068614\n",
      "------------------ Epoch finished ------------------\n",
      "Saving epoch 9 ...\n",
      "Checkpoint saved successfully! Time: 0 s\n",
      "Epoch:  10 Batch:  0 loss: 5.131693\n",
      "Epoch:  10 Batch:  10 loss: 4.13009\n",
      "Epoch:  10 Batch:  20 loss: 3.9968057\n",
      "Epoch:  10 Batch:  30 loss: 3.9193351\n",
      "Epoch:  10 Batch:  40 loss: 4.4130893\n",
      "Epoch:  10 Batch:  50 loss: 4.9265504\n",
      "Epoch:  10 Batch:  60 loss: 6.8572693\n",
      "Epoch:  10 Batch:  70 loss: 3.7393112\n",
      "Epoch:  10 Batch:  80 loss: 4.8540297\n",
      "Epoch:  10 Batch:  90 loss: 4.0963497\n",
      "Epoch:  10 Batch:  100 loss: 4.540116\n",
      "Epoch:  10 Batch:  110 loss: 3.9933088\n",
      "Epoch:  10 Batch:  120 loss: 5.261448\n",
      "Epoch:  10 Batch:  130 loss: 3.1881301\n",
      "Epoch:  10 Batch:  140 loss: 3.9862516\n",
      "Epoch:  10 Batch:  150 loss: 6.1666236\n",
      "Epoch:  10 Batch:  160 loss: 3.650816\n",
      "Epoch:  10 Batch:  170 loss: 5.19779\n",
      "Epoch:  10 Batch:  180 loss: 4.240602\n",
      "Epoch:  10 Batch:  190 loss: 3.7178717\n",
      "Epoch:  10 Batch:  200 loss: 3.805092\n",
      "Epoch:  10 Batch:  210 loss: 1.574647\n",
      "Epoch:  10 Batch:  220 loss: 3.5095434\n",
      "Epoch:  10 Batch:  230 loss: 3.0304906\n",
      "Epoch:  10 Batch:  240 loss: 3.038385\n",
      "Epoch:  10 Batch:  250 loss: 7.6412854\n",
      "Epoch:  10 Batch:  260 loss: 3.0833013\n",
      "Epoch:  10 Batch:  270 loss: 3.5834446\n",
      "Epoch:  10 Batch:  280 loss: 4.023017\n",
      "Epoch:  10 Batch:  290 loss: 4.27306\n",
      "Epoch:  10 Batch:  300 loss: 2.7607942\n",
      "Epoch:  10 Batch:  310 loss: 7.5666685\n",
      "Epoch:  10 Batch:  320 loss: 2.9487686\n",
      "Epoch:  10 Batch:  330 loss: 5.5539274\n",
      "Epoch:  10 Batch:  340 loss: 3.3507113\n",
      "Epoch:  10 Batch:  350 loss: 3.1758618\n",
      "------------------ Epoch finished ------------------\n",
      "Saving epoch 10 ...\n",
      "Checkpoint saved successfully! Time: 1 s\n",
      "Epoch:  11 Batch:  0 loss: 4.778328\n",
      "Epoch:  11 Batch:  10 loss: 3.7786667\n",
      "Epoch:  11 Batch:  20 loss: 3.664724\n",
      "Epoch:  11 Batch:  30 loss: 3.5184088\n",
      "Epoch:  11 Batch:  40 loss: 3.9160101\n",
      "Epoch:  11 Batch:  50 loss: 4.5943527\n",
      "Epoch:  11 Batch:  60 loss: 6.0332274\n",
      "Epoch:  11 Batch:  70 loss: 3.381282\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  11 Batch:  80 loss: 4.1923842\n",
      "Epoch:  11 Batch:  90 loss: 3.6423664\n",
      "Epoch:  11 Batch:  100 loss: 4.1134276\n",
      "Epoch:  11 Batch:  110 loss: 3.7582235\n",
      "Epoch:  11 Batch:  120 loss: 4.8457003\n",
      "Epoch:  11 Batch:  130 loss: 2.877355\n",
      "Epoch:  11 Batch:  140 loss: 3.7970853\n",
      "Epoch:  11 Batch:  150 loss: 5.740725\n",
      "Epoch:  11 Batch:  160 loss: 3.2263877\n",
      "Epoch:  11 Batch:  170 loss: 4.9759407\n",
      "Epoch:  11 Batch:  180 loss: 3.774871\n",
      "Epoch:  11 Batch:  190 loss: 3.4383008\n",
      "Epoch:  11 Batch:  200 loss: 3.386059\n",
      "Epoch:  11 Batch:  210 loss: 1.2881382\n",
      "Epoch:  11 Batch:  220 loss: 3.0075805\n",
      "Epoch:  11 Batch:  230 loss: 2.6064641\n",
      "Epoch:  11 Batch:  240 loss: 2.9139407\n",
      "Epoch:  11 Batch:  250 loss: 7.066177\n",
      "Epoch:  11 Batch:  260 loss: 2.8900404\n",
      "Epoch:  11 Batch:  270 loss: 3.2054589\n",
      "Epoch:  11 Batch:  280 loss: 3.829527\n",
      "Epoch:  11 Batch:  290 loss: 3.8255289\n",
      "Epoch:  11 Batch:  300 loss: 2.5727015\n",
      "Epoch:  11 Batch:  310 loss: 7.3298564\n",
      "Epoch:  11 Batch:  320 loss: 2.6599455\n",
      "Epoch:  11 Batch:  330 loss: 5.095876\n",
      "Epoch:  11 Batch:  340 loss: 2.8511317\n",
      "Epoch:  11 Batch:  350 loss: 2.894471\n",
      "------------------ Epoch finished ------------------\n",
      "Saving epoch 11 ...\n",
      "Checkpoint saved successfully! Time: 0 s\n",
      "Epoch:  12 Batch:  0 loss: 4.44753\n",
      "Epoch:  12 Batch:  10 loss: 3.4598305\n",
      "Epoch:  12 Batch:  20 loss: 3.344205\n",
      "Epoch:  12 Batch:  30 loss: 3.3183215\n",
      "Epoch:  12 Batch:  40 loss: 3.6219704\n",
      "Epoch:  12 Batch:  50 loss: 4.235714\n",
      "Epoch:  12 Batch:  60 loss: 5.64326\n",
      "Epoch:  12 Batch:  70 loss: 2.9781394\n",
      "Epoch:  12 Batch:  80 loss: 3.616983\n",
      "Epoch:  12 Batch:  90 loss: 3.4545734\n",
      "Epoch:  12 Batch:  100 loss: 3.747005\n",
      "Epoch:  12 Batch:  110 loss: 3.4522398\n",
      "Epoch:  12 Batch:  120 loss: 4.5094023\n",
      "Epoch:  12 Batch:  130 loss: 2.5008805\n",
      "Epoch:  12 Batch:  140 loss: 3.4680557\n",
      "Epoch:  12 Batch:  150 loss: 5.315587\n",
      "Epoch:  12 Batch:  160 loss: 3.0279827\n",
      "Epoch:  12 Batch:  170 loss: 4.7837963\n",
      "Epoch:  12 Batch:  180 loss: 3.531322\n",
      "Epoch:  12 Batch:  190 loss: 3.0084083\n",
      "Epoch:  12 Batch:  200 loss: 2.9933362\n",
      "Epoch:  12 Batch:  210 loss: 1.020072\n",
      "Epoch:  12 Batch:  220 loss: 2.775246\n",
      "Epoch:  12 Batch:  230 loss: 2.321793\n",
      "Epoch:  12 Batch:  240 loss: 2.328722\n",
      "Epoch:  12 Batch:  250 loss: 6.825158\n",
      "Epoch:  12 Batch:  260 loss: 2.5566683\n",
      "Epoch:  12 Batch:  270 loss: 2.899415\n",
      "Epoch:  12 Batch:  280 loss: 3.4373746\n",
      "Epoch:  12 Batch:  290 loss: 3.7118335\n",
      "Epoch:  12 Batch:  300 loss: 2.1539195\n",
      "Epoch:  12 Batch:  310 loss: 6.967531\n",
      "Epoch:  12 Batch:  320 loss: 2.3940525\n",
      "Epoch:  12 Batch:  330 loss: 4.7674274\n",
      "Epoch:  12 Batch:  340 loss: 2.5086107\n",
      "Epoch:  12 Batch:  350 loss: 2.6270394\n",
      "------------------ Epoch finished ------------------\n",
      "Saving epoch 12 ...\n",
      "Checkpoint saved successfully! Time: 0 s\n",
      "Epoch:  13 Batch:  0 loss: 4.1567616\n",
      "Epoch:  13 Batch:  10 loss: 3.1310883\n",
      "Epoch:  13 Batch:  20 loss: 3.065856\n",
      "Epoch:  13 Batch:  30 loss: 3.047485\n",
      "Epoch:  13 Batch:  40 loss: 3.2960095\n",
      "Epoch:  13 Batch:  50 loss: 3.880793\n",
      "Epoch:  13 Batch:  60 loss: 5.3551397\n",
      "Epoch:  13 Batch:  70 loss: 2.862357\n",
      "Epoch:  13 Batch:  80 loss: 3.202365\n",
      "Epoch:  13 Batch:  90 loss: 3.1386664\n",
      "Epoch:  13 Batch:  100 loss: 3.350564\n",
      "Epoch:  13 Batch:  110 loss: 3.2572014\n",
      "Epoch:  13 Batch:  120 loss: 4.228532\n",
      "Epoch:  13 Batch:  130 loss: 2.2178252\n",
      "Epoch:  13 Batch:  140 loss: 3.2054367\n",
      "Epoch:  13 Batch:  150 loss: 4.998806\n",
      "Epoch:  13 Batch:  160 loss: 2.6728094\n",
      "Epoch:  13 Batch:  170 loss: 4.382204\n",
      "Epoch:  13 Batch:  180 loss: 3.2407434\n",
      "Epoch:  13 Batch:  190 loss: 2.75544\n",
      "Epoch:  13 Batch:  200 loss: 2.723791\n",
      "Epoch:  13 Batch:  210 loss: 0.8920345\n",
      "Epoch:  13 Batch:  220 loss: 2.3994172\n",
      "Epoch:  13 Batch:  230 loss: 2.199328\n",
      "Epoch:  13 Batch:  240 loss: 2.0755622\n",
      "Epoch:  13 Batch:  250 loss: 6.613892\n",
      "Epoch:  13 Batch:  260 loss: 2.25978\n",
      "Epoch:  13 Batch:  270 loss: 2.776303\n",
      "Epoch:  13 Batch:  280 loss: 3.1818\n",
      "Epoch:  13 Batch:  290 loss: 3.4932544\n",
      "Epoch:  13 Batch:  300 loss: 1.925734\n",
      "Epoch:  13 Batch:  310 loss: 6.6837173\n",
      "Epoch:  13 Batch:  320 loss: 2.1202126\n",
      "Epoch:  13 Batch:  330 loss: 4.590882\n",
      "Epoch:  13 Batch:  340 loss: 2.252583\n",
      "Epoch:  13 Batch:  350 loss: 2.4038467\n",
      "------------------ Epoch finished ------------------\n",
      "Saving epoch 13 ...\n",
      "Checkpoint saved successfully! Time: 0 s\n",
      "Epoch:  14 Batch:  0 loss: 3.880571\n",
      "Epoch:  14 Batch:  10 loss: 2.8604603\n",
      "Epoch:  14 Batch:  20 loss: 2.8255477\n",
      "Epoch:  14 Batch:  30 loss: 2.9012268\n",
      "Epoch:  14 Batch:  40 loss: 2.936669\n",
      "Epoch:  14 Batch:  50 loss: 3.2168684\n",
      "Epoch:  14 Batch:  60 loss: 5.140052\n",
      "Epoch:  14 Batch:  70 loss: 2.4620817\n",
      "Epoch:  14 Batch:  80 loss: 2.952487\n",
      "Epoch:  14 Batch:  90 loss: 2.9438195\n",
      "Epoch:  14 Batch:  100 loss: 3.1240664\n",
      "Epoch:  14 Batch:  110 loss: 3.0774777\n",
      "Epoch:  14 Batch:  120 loss: 4.025303\n",
      "Epoch:  14 Batch:  130 loss: 2.021369\n",
      "Epoch:  14 Batch:  140 loss: 3.0842884\n",
      "Epoch:  14 Batch:  150 loss: 4.6048517\n",
      "Epoch:  14 Batch:  160 loss: 2.5353024\n",
      "Epoch:  14 Batch:  170 loss: 4.2239475\n",
      "Epoch:  14 Batch:  180 loss: 2.8747714\n",
      "Epoch:  14 Batch:  190 loss: 2.4598413\n",
      "Epoch:  14 Batch:  200 loss: 2.436836\n",
      "Epoch:  14 Batch:  210 loss: 0.78305703\n",
      "Epoch:  14 Batch:  220 loss: 1.9153198\n",
      "Epoch:  14 Batch:  230 loss: 2.0095282\n",
      "Epoch:  14 Batch:  240 loss: 1.8999755\n",
      "Epoch:  14 Batch:  250 loss: 6.2582836\n",
      "Epoch:  14 Batch:  260 loss: 2.0629244\n",
      "Epoch:  14 Batch:  270 loss: 2.4521856\n",
      "Epoch:  14 Batch:  280 loss: 2.9534311\n",
      "Epoch:  14 Batch:  290 loss: 3.2297688\n",
      "Epoch:  14 Batch:  300 loss: 1.7003953\n",
      "Epoch:  14 Batch:  310 loss: 6.539487\n",
      "Epoch:  14 Batch:  320 loss: 1.9835516\n",
      "Epoch:  14 Batch:  330 loss: 4.4156723\n",
      "Epoch:  14 Batch:  340 loss: 1.9764465\n",
      "Epoch:  14 Batch:  350 loss: 2.2537012\n",
      "------------------ Epoch finished ------------------\n",
      "Saving epoch 14 ...\n",
      "Checkpoint saved successfully! Time: 0 s\n",
      "Epoch:  15 Batch:  0 loss: 3.6673453\n",
      "Epoch:  15 Batch:  10 loss: 2.5524242\n",
      "Epoch:  15 Batch:  20 loss: 2.706715\n",
      "Epoch:  15 Batch:  30 loss: 2.783528\n",
      "Epoch:  15 Batch:  40 loss: 2.6160216\n",
      "Epoch:  15 Batch:  50 loss: 2.9431918\n",
      "Epoch:  15 Batch:  60 loss: 4.8106728\n",
      "Epoch:  15 Batch:  70 loss: 2.1850245\n",
      "Epoch:  15 Batch:  80 loss: 2.614742\n",
      "Epoch:  15 Batch:  90 loss: 2.6905656\n",
      "Epoch:  15 Batch:  100 loss: 2.8799958\n",
      "Epoch:  15 Batch:  110 loss: 2.7522821\n",
      "Epoch:  15 Batch:  120 loss: 3.6727135\n",
      "Epoch:  15 Batch:  130 loss: 1.7975041\n",
      "Epoch:  15 Batch:  140 loss: 2.9164364\n",
      "Epoch:  15 Batch:  150 loss: 4.534342\n",
      "Epoch:  15 Batch:  160 loss: 2.322896\n",
      "Epoch:  15 Batch:  170 loss: 3.8642535\n",
      "Epoch:  15 Batch:  180 loss: 2.681515\n",
      "Epoch:  15 Batch:  190 loss: 2.2991285\n",
      "Epoch:  15 Batch:  200 loss: 2.1714146\n",
      "Epoch:  15 Batch:  210 loss: 0.66065085\n",
      "Epoch:  15 Batch:  220 loss: 1.6754767\n",
      "Epoch:  15 Batch:  230 loss: 1.7668866\n",
      "Epoch:  15 Batch:  240 loss: 1.7104968\n",
      "Epoch:  15 Batch:  250 loss: 5.9151807\n",
      "Epoch:  15 Batch:  260 loss: 1.9537709\n",
      "Epoch:  15 Batch:  270 loss: 2.2826316\n",
      "Epoch:  15 Batch:  280 loss: 2.9267957\n",
      "Epoch:  15 Batch:  290 loss: 2.869701\n",
      "Epoch:  15 Batch:  300 loss: 1.5429666\n",
      "Epoch:  15 Batch:  310 loss: 6.05217\n",
      "Epoch:  15 Batch:  320 loss: 1.8564143\n",
      "Epoch:  15 Batch:  330 loss: 4.4247417\n",
      "Epoch:  15 Batch:  340 loss: 1.867896\n",
      "Epoch:  15 Batch:  350 loss: 2.1404097\n",
      "------------------ Epoch finished ------------------\n",
      "Saving epoch 15 ...\n",
      "Checkpoint saved successfully! Time: 0 s\n",
      "Epoch:  16 Batch:  0 loss: 3.3220108\n",
      "Epoch:  16 Batch:  10 loss: 2.3328452\n",
      "Epoch:  16 Batch:  20 loss: 2.4333138\n",
      "Epoch:  16 Batch:  30 loss: 2.568897\n",
      "Epoch:  16 Batch:  40 loss: 2.422577\n",
      "Epoch:  16 Batch:  50 loss: 3.08607\n",
      "Epoch:  16 Batch:  60 loss: 4.369436\n",
      "Epoch:  16 Batch:  70 loss: 2.1007078\n",
      "Epoch:  16 Batch:  80 loss: 2.3985221\n",
      "Epoch:  16 Batch:  90 loss: 2.4370964\n",
      "Epoch:  16 Batch:  100 loss: 2.519453\n",
      "Epoch:  16 Batch:  110 loss: 2.7639952\n",
      "Epoch:  16 Batch:  120 loss: 3.4872353\n",
      "Epoch:  16 Batch:  130 loss: 1.6563305\n",
      "Epoch:  16 Batch:  140 loss: 2.723637\n",
      "Epoch:  16 Batch:  150 loss: 4.322647\n",
      "Epoch:  16 Batch:  160 loss: 2.0714374\n",
      "Epoch:  16 Batch:  170 loss: 3.6397877\n",
      "Epoch:  16 Batch:  180 loss: 2.3431861\n",
      "Epoch:  16 Batch:  190 loss: 2.1130054\n",
      "Epoch:  16 Batch:  200 loss: 2.4287536\n",
      "Epoch:  16 Batch:  210 loss: 0.5730523\n",
      "Epoch:  16 Batch:  220 loss: 1.5071046\n",
      "Epoch:  16 Batch:  230 loss: 1.5782082\n",
      "Epoch:  16 Batch:  240 loss: 1.5005401\n",
      "Epoch:  16 Batch:  250 loss: 5.6159973\n",
      "Epoch:  16 Batch:  260 loss: 1.6908988\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  16 Batch:  270 loss: 2.1311207\n",
      "Epoch:  16 Batch:  280 loss: 2.6219087\n",
      "Epoch:  16 Batch:  290 loss: 2.6991944\n",
      "Epoch:  16 Batch:  300 loss: 1.4430351\n",
      "Epoch:  16 Batch:  310 loss: 5.8331466\n",
      "Epoch:  16 Batch:  320 loss: 1.7558779\n",
      "Epoch:  16 Batch:  330 loss: 4.0936885\n",
      "Epoch:  16 Batch:  340 loss: 1.5836421\n",
      "Epoch:  16 Batch:  350 loss: 1.9084389\n",
      "------------------ Epoch finished ------------------\n",
      "Saving epoch 16 ...\n",
      "Checkpoint saved successfully! Time: 0 s\n",
      "Epoch:  17 Batch:  0 loss: 3.0115273\n",
      "Epoch:  17 Batch:  10 loss: 2.1291833\n",
      "Epoch:  17 Batch:  20 loss: 2.302876\n",
      "Epoch:  17 Batch:  30 loss: 2.2314527\n",
      "Epoch:  17 Batch:  40 loss: 2.3511784\n",
      "Epoch:  17 Batch:  50 loss: 2.445254\n",
      "Epoch:  17 Batch:  60 loss: 4.0822487\n",
      "Epoch:  17 Batch:  70 loss: 1.8677787\n",
      "Epoch:  17 Batch:  80 loss: 2.1842945\n",
      "Epoch:  17 Batch:  90 loss: 2.3169963\n",
      "Epoch:  17 Batch:  100 loss: 2.318355\n",
      "Epoch:  17 Batch:  110 loss: 2.2603767\n",
      "Epoch:  17 Batch:  120 loss: 3.220751\n",
      "Epoch:  17 Batch:  130 loss: 1.4829985\n",
      "Epoch:  17 Batch:  140 loss: 2.5826178\n",
      "Epoch:  17 Batch:  150 loss: 4.187059\n",
      "Epoch:  17 Batch:  160 loss: 1.8835182\n",
      "Epoch:  17 Batch:  170 loss: 3.3584454\n",
      "Epoch:  17 Batch:  180 loss: 2.3261335\n",
      "Epoch:  17 Batch:  190 loss: 1.784327\n",
      "Epoch:  17 Batch:  200 loss: 1.7842554\n",
      "Epoch:  17 Batch:  210 loss: 0.479006\n",
      "Epoch:  17 Batch:  220 loss: 1.3617462\n",
      "Epoch:  17 Batch:  230 loss: 1.5462542\n",
      "Epoch:  17 Batch:  240 loss: 1.4197524\n",
      "Epoch:  17 Batch:  250 loss: 5.2745166\n",
      "Epoch:  17 Batch:  260 loss: 1.547734\n",
      "Epoch:  17 Batch:  270 loss: 2.0656352\n",
      "Epoch:  17 Batch:  280 loss: 2.4570782\n",
      "Epoch:  17 Batch:  290 loss: 2.6544862\n",
      "Epoch:  17 Batch:  300 loss: 1.4236318\n",
      "Epoch:  17 Batch:  310 loss: 5.588238\n",
      "Epoch:  17 Batch:  320 loss: 1.6435333\n",
      "Epoch:  17 Batch:  330 loss: 3.9637177\n",
      "Epoch:  17 Batch:  340 loss: 1.4149252\n",
      "Epoch:  17 Batch:  350 loss: 1.9893923\n",
      "------------------ Epoch finished ------------------\n",
      "Saving epoch 17 ...\n",
      "Checkpoint saved successfully! Time: 0 s\n",
      "Epoch:  18 Batch:  0 loss: 3.0091326\n",
      "Epoch:  18 Batch:  10 loss: 1.8321135\n",
      "Epoch:  18 Batch:  20 loss: 2.0879471\n",
      "Epoch:  18 Batch:  30 loss: 2.1355133\n",
      "Epoch:  18 Batch:  40 loss: 2.0204031\n",
      "Epoch:  18 Batch:  50 loss: 2.38262\n",
      "Epoch:  18 Batch:  60 loss: 3.8678784\n",
      "Epoch:  18 Batch:  70 loss: 1.56888\n",
      "Epoch:  18 Batch:  80 loss: 1.9798646\n",
      "Epoch:  18 Batch:  90 loss: 2.1018636\n",
      "Epoch:  18 Batch:  100 loss: 2.2982273\n",
      "Epoch:  18 Batch:  110 loss: 2.1675406\n",
      "Epoch:  18 Batch:  120 loss: 2.8636093\n",
      "Epoch:  18 Batch:  130 loss: 1.361768\n",
      "Epoch:  18 Batch:  140 loss: 2.3205743\n",
      "Epoch:  18 Batch:  150 loss: 3.7472308\n",
      "Epoch:  18 Batch:  160 loss: 1.6799997\n",
      "Epoch:  18 Batch:  170 loss: 3.1947913\n",
      "Epoch:  18 Batch:  180 loss: 2.123753\n",
      "Epoch:  18 Batch:  190 loss: 1.6750733\n",
      "Epoch:  18 Batch:  200 loss: 1.8761798\n",
      "Epoch:  18 Batch:  210 loss: 0.42288712\n",
      "Epoch:  18 Batch:  220 loss: 1.0978131\n",
      "Epoch:  18 Batch:  230 loss: 1.2352601\n",
      "Epoch:  18 Batch:  240 loss: 1.4001242\n",
      "Epoch:  18 Batch:  250 loss: 5.1935754\n",
      "Epoch:  18 Batch:  260 loss: 1.4484968\n",
      "Epoch:  18 Batch:  270 loss: 1.9400647\n",
      "Epoch:  18 Batch:  280 loss: 2.2550993\n",
      "Epoch:  18 Batch:  290 loss: 2.3620305\n",
      "Epoch:  18 Batch:  300 loss: 1.1498988\n",
      "Epoch:  18 Batch:  310 loss: 5.529161\n",
      "Epoch:  18 Batch:  320 loss: 1.3332232\n",
      "Epoch:  18 Batch:  330 loss: 3.7617617\n",
      "Epoch:  18 Batch:  340 loss: 1.2755066\n",
      "Epoch:  18 Batch:  350 loss: 1.7557886\n",
      "------------------ Epoch finished ------------------\n",
      "Saving epoch 18 ...\n",
      "Checkpoint saved successfully! Time: 0 s\n",
      "Epoch:  19 Batch:  0 loss: 2.6983533\n",
      "Epoch:  19 Batch:  10 loss: 1.7226715\n",
      "Epoch:  19 Batch:  20 loss: 1.9190505\n",
      "Epoch:  19 Batch:  30 loss: 1.909167\n",
      "Epoch:  19 Batch:  40 loss: 2.1004364\n",
      "Epoch:  19 Batch:  50 loss: 2.2606895\n",
      "Epoch:  19 Batch:  60 loss: 3.5257735\n",
      "Epoch:  19 Batch:  70 loss: 1.405686\n",
      "Epoch:  19 Batch:  80 loss: 1.8155103\n",
      "Epoch:  19 Batch:  90 loss: 1.9874989\n",
      "Epoch:  19 Batch:  100 loss: 1.9374747\n",
      "Epoch:  19 Batch:  110 loss: 2.0237505\n",
      "Epoch:  19 Batch:  120 loss: 2.7731824\n",
      "Epoch:  19 Batch:  130 loss: 1.212418\n",
      "Epoch:  19 Batch:  140 loss: 2.266168\n",
      "Epoch:  19 Batch:  150 loss: 3.6799743\n",
      "Epoch:  19 Batch:  160 loss: 1.6295875\n",
      "Epoch:  19 Batch:  170 loss: 2.9888558\n",
      "Epoch:  19 Batch:  180 loss: 1.8418305\n",
      "Epoch:  19 Batch:  190 loss: 1.7263875\n",
      "Epoch:  19 Batch:  200 loss: 1.6116652\n",
      "Epoch:  19 Batch:  210 loss: 0.37197194\n",
      "Epoch:  19 Batch:  220 loss: 0.96317273\n",
      "Epoch:  19 Batch:  230 loss: 1.1476853\n",
      "Epoch:  19 Batch:  240 loss: 1.1113021\n",
      "Epoch:  19 Batch:  250 loss: 5.0783486\n",
      "Epoch:  19 Batch:  260 loss: 1.3605837\n",
      "Epoch:  19 Batch:  270 loss: 1.8196231\n",
      "Epoch:  19 Batch:  280 loss: 2.1460373\n",
      "Epoch:  19 Batch:  290 loss: 2.3459492\n",
      "Epoch:  19 Batch:  300 loss: 1.025651\n",
      "Epoch:  19 Batch:  310 loss: 5.122855\n",
      "Epoch:  19 Batch:  320 loss: 1.4530594\n",
      "Epoch:  19 Batch:  330 loss: 3.7993844\n",
      "Epoch:  19 Batch:  340 loss: 1.1435797\n",
      "Epoch:  19 Batch:  350 loss: 1.5599712\n",
      "------------------ Epoch finished ------------------\n",
      "Saving epoch 19 ...\n",
      "Checkpoint saved successfully! Time: 0 s\n",
      "------------------ Finished!------------------\n"
     ]
    }
   ],
   "source": [
    "\n",
    "epoch = 20\n",
    "batch_size = 50\n",
    "prev_batch = 0\n",
    "\n",
    "sess = tf.Session()\n",
    "\n",
    "latestSnapshot = tf.train.latest_checkpoint('./checkpoints')\n",
    "\n",
    "if latestSnapshot != None:\n",
    "    saver.restore(sess, latestSnapshot)\n",
    "else:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "t0 = time()\n",
    "\n",
    "print(\"------------------ Training ------------------\")\n",
    "for ep in range(epoch):\n",
    "    for i in range(len(x_train) // batch_size):\n",
    "        t1 = time()\n",
    "        X_batch, y_batch = next_batch(prev_batch, batch_size)\n",
    "        prev_batch+=batch_size\n",
    "        sparse = toSparse(y_batch)\n",
    "        rate = 0.0001\n",
    "        (_, lossVal) = sess.run([optimizer,loss], feed_dict={Input: X_batch, gtTexts : sparse, \n",
    "                                                             seqLen : [32] * batch_size,\n",
    "                                                             learningRate : rate})\n",
    "        if(i % 10 == 0):\n",
    "            print(\"Epoch: \",ep,\"Batch: \",i, \"loss:\", lossVal)  \n",
    "        t2 = time()\n",
    "    print(\"------------------ Epoch finished ------------------\")\n",
    "    print(\"Saving epoch\",ep,\"...\")\n",
    "    saver.save(sess, \"./checkpoints/HTRModel\")\n",
    "    print(\"Checkpoint saved successfully!\", \"Time:\" '%2d s'%(t2 - t1))\n",
    "    prev_batch = 0\n",
    "    t3 = time()\n",
    "print(\"------------------ Finished!------------------\")\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validation on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "labels = predict(x_test_tf) #Infer labels from the decoder output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8157849089332176\n"
     ]
    }
   ],
   "source": [
    "plt.title(labels[7])\n",
    "plt.imshow(x_test[7], cmap=plt.cm.gray)\n",
    "plt.show()\n",
    "\n",
    "#This accuracy function evaluates the accuracy on character predition, \n",
    "# not on full-name prediction\n",
    "\n",
    "print(\"Accuracy:\",accuracy(y_test, labels)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
