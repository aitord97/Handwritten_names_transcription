{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import cv2\n",
    "import pandas\n",
    "import requests\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "import urllib.request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "#put ground truth texts into sparse tensor for ctc_loss\n",
    "def toSparse(texts):\n",
    "    indices = []\n",
    "    values = []\n",
    "    shape = [len(texts), 0] # last entry must be max(labelList[i])\n",
    "\n",
    "    # go over all texts\n",
    "    for (batchElement, text) in enumerate(texts):\n",
    "        # convert to string of label (i.e. class-ids)\n",
    "        print(text)\n",
    "        labelStr = [charList.index(c) for c in text]\n",
    "      \n",
    "        # sparse tensor must have size of max. label-string\n",
    "        if len(labelStr) > shape[1]:\n",
    "            shape[1] = len(labelStr)\n",
    "        # put each label into sparse tensor\n",
    "        for (i, label) in enumerate(labelStr):\n",
    "            print(label)\n",
    "            indices.append([batchElement, i])\n",
    "            values.append(label)\n",
    "\n",
    "    return (indices, values, shape)\n",
    "\n",
    "\n",
    "#extract texts from output of CTC decoder\n",
    "def decoderOutputToText(self, ctcOutput, batchSize):\n",
    "    \n",
    "    \n",
    "    # contains string of labels for each batch element\n",
    "    encodedLabelStrs = [[] for i in range(batchSize)]\n",
    "\n",
    "    # word beam search: label strings terminated by blank\n",
    "    if self.decoderType == DecoderType.WordBeamSearch:\n",
    "        blank=len(self.charList)\n",
    "        for b in range(batchSize):\n",
    "            for label in ctcOutput[b]:\n",
    "                if label==blank:\n",
    "                    break\n",
    "                encodedLabelStrs[b].append(label)\n",
    "\n",
    "    # TF decoders: label strings are contained in sparse tensor\n",
    "    else:\n",
    "        # ctc returns tuple, first element is SparseTensor \n",
    "        decoded=ctcOutput[0][0] \n",
    "\n",
    "        # go over all indices and save mapping: batch -> values\n",
    "        idxDict = { b : [] for b in range(batchSize) }\n",
    "        for (idx, idx2d) in enumerate(decoded.indices):\n",
    "            label = decoded.values[idx]\n",
    "            batchElement = idx2d[0] # index according to [b,t]\n",
    "            encodedLabelStrs[batchElement].append(label)\n",
    "\n",
    "    # map labels to chars for all batch elements\n",
    "    return [str().join([self.charList[c] for c in labelStr]) for labelStr in encodedLabelStrs]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_data = np.load('HandwrittenNames-Dataset/HandwrittenNames_data.npz',allow_pickle=True)['data']\n",
    "Y_labels = np.load('HandwrittenNames-Dataset/HandwrittenNames_labels.npz',allow_pickle=True)['data']\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_data0 = []\n",
    "for x in X_data:\n",
    "    X_data0.append(np.resize(x,(18,310)))\n",
    "    \n",
    "X_data = np.array(X_data0)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "def next_batch(prev_batch, batch_size):\n",
    "    return np.array(x_train[prev_batch:prev_batch + batch_size]), y_train[prev_batch:prev_batch + batch_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXAAAABICAYAAADvR65LAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjAsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+17YcXAAAaLElEQVR4nO2de5hU1bXgf6urqrvt5tFNK53mNcoFvqAtbwggt/kiNyIm8wkJBk2IJLkJn5h8OGYM44TMhfG2N844mVxvxkRihqhgronG9JC0USGKCirySHjJQySAPBto3vSjqs6aP+rs07uqq7uroW0o3L/vO19Xncfea53dtfY6a6+9j6gqDofD4cg+ci61AA6Hw+G4MJwBdzgcjizFGXCHw+HIUpwBdzgcjizFGXCHw+HIUpwBdzgcjizFGXCHw+HIUpwBd2QFIrJHRP6hhWPXiYgnIj9L2X+tiKiIhFP2PyUilf7nr4tIXETOishpEdkoIl9oqQz/WhWRMdY5A0REre8rRaTeL9Nsf+iYO+FwNOEMuONK4G7gBHCniORdwPXvqGoXoAj4GfCciBS1cn4tUNlGmd9V1S7W9h8vQC6Ho1WcAXdcCdwN/BCIAhdsKFXVA5YAhcDAVk59GhgiIhMvtC6HoyNwBtyR1YjI3wN9gOeA35Iw5hdaVgj4BomOYG8rp54H/gV4+ELrcjg6AmfAHdnOLOBPqnoC+DUwRUR6trOMsSJyEqgH/hcwU1Vr2rhmEdBPRKa0cPzfROSktf1zO2VyONrEGXBH1iIiVwF3AM8CqOo7wD7gK/4pMf9vJOXSCAkv2/CuqhYBxcAy4O/bqltVG4B/9jdJc8pcVS2ytv+WmVYOR+Y4A+7IZqYB3YCfichhETkM9KYpjHKIhKG+NuW660gTIlHVs8C9wNdEZHgG9f8K6O7L4XB0Os6AO7KJiIjkmw34R2AxcCMwzN9uAoaJyI2qGgd+BzwsIiUiEhGRu4DrgT+lq0BVjwO/BP6pLWFUNQYsBP7LxavmcLQfZ8Ad2cRLQJ21TQT+VVUPW9t64GUSsXFIeNS1wCagBvgu8HlVPdJKPf8K3CYiQzKQ6d9JePqp/J+UPPD1mSjocLQHcS90cDgcjuzEeeAOh8ORpTgD7nA4HFnKRRlwEblVRHaIyC4RebCjhHI4HA5H21xwDNyftbYT+BywH1gL3KWq73eceA6Hw+FoiYvxwMcAu1R1t6o2kpjKfHvHiOVwOByOtgi3fUqL9AY+sr7vBz6TepKIzAZmAxQWFo789Kc/fRFVOhwOxyeP9evXH1PVa1L3X4wBTzd9uFk8RlV/AfwCYNSoUbp27VpE0l3aHM/zyMlpekiIx+OEQqHmlarieR6hUIhoNEokkjpzuvXyVTWQyXw2dcViMUKhUDOZU2Wzy0j9bs615W9JF3Ot+WvqiMfjqCrhcFOT2WW0JI+qBp/NPfI8DxFBRGhsbCQ3NxeAWCwWlG9k8DwPoJncnuehqoRCIeLxOCKSVL/necTj8aAtTDnmHFNXqtzpdEu9tw7HJw0RSbu42sWEUPYDfa3vfYCDGQiScQWpP2zzg66vr+fo0aN4nkc0GkVEgmORSCQwFpmUb643Bsk23p7nEQ6Hk46bzchmOg9zna2n53k0NDQE5xrdU413PB4PZDby2AbWdCLhcJhotGkJD7uMnJwcYrEYsVgsMKimzpycnOAeqWqSzrm5uTQ0NAAEBtWWIRQKJXUSplzT8UWjUUKhULO2ysnJCdrC3C/7noXDYezxl8bGxqR2s3WzO1eHw9HExRjwtcBA/20oucCdJBYCahVjLNrC9kKBwBAAnD9/npEjR/KTn/yESCTSzBCk8+hawlxvjJwxlqYsIDCI9mYbG1OfuS4WiwWy5+XlBfLb59mdgfnueV7gsUajUc6dO8e6detYt24dZ8+eBRJG1nQU5nrzORwOEw6HA+Nq3xPP82hsbEREyMvLC+Q3MpoyRSTpCcbc91gsFhhh2ys3989c73leUluZJw+z2eXaXntubm7w2b639jXOgDscyVywAffXgfgu8AqwDfitqm5t6zrzuN4WqZ667YXl5+eTl5fH1q1bicViwbGGhoaMy4cmQ7F//34mTpzIfffdx7vvvhuEK/Lz8wHShjpae5Iw3qXtuUKTYa+vr0/qDMy5xoDV19dTX1/P5z73ORYuXMjNN9/MzJkzOX36dCCP3anYZafKZrzsnJwccnNzm3nExijaZZryzL0VkaDjMIbcHDdtEgqFWLVqFYcPHw46Q9MBhsPhwJNPDbfU1dUFTxWmvGg0mtRJpD71OByOBBf1i1DVl1R1kKr+napmtLh9e0IoduzWNngFBQVMmDAheHyHhJdpvN1MvfycnBzOnDnDV77yFbZs2cKSJUuYOHEiP/rRjwJP0vYGo9FoYGyM4TV12xh5jSEyxjIcDhOLxcjPzw88bjssYbzN/Px8KisrGTduHK+++irV1dXs2rWLz3/+80kG38gEJHnNxkjasXdIdAzGuHqeFxhj+37Ycth62mGchoYGwuFwM+/7l7/8JTt27Ai+252p0dWMK5j7mpeXF4RaTMeXl5eX5Ombdrflcjgcbiamw+FwZC2dbsDbE8dMjYObz7W1taxYsYJp06YlZVKoKg0NDYEn3hY1NTXcfvvtbNmyheXLl7Nt2zYef/xxHn74YaqqqgLv1TwJRCKRpKwK4xnm5uby1ltv8Y1vfCN41DcZGG+++SY7d+4MwgNmoNCEEUwYw/ZO9+zZw2uvvcbXvvY1AD772c/y/PPPs337diorK4OBSlVN8rxNWMOEHYxHXV1dzWuvvRaEhCDhZdsZJ6kDnyaeDgQedzwe5/nnn2fnzp3U1dUFehhPPBKJBOES4y2nes32wHAsFqOhoYHjx49z8OBBTp48ybFjxwKZjAduZ7w4HI4mOt2AtyeEYhsUaBq027BhAwcOHKCsrAxoelS3s1Ey4aGHHuL1119nwoQJjBgxgtLSUu655x4mT55MZWUldXV1gXGyO5FoNJoUejh+/Dhf/vKX6dKlS/Cob2Surq5m3LhxwSCknUWSGmc2MeY5c+YwYMAAhg8fHmR6DB48mAcffJANGzYQiUSC1EYjl0nLM0bXDv2cPn2aSZMm8corrwQGNRKJJGW/2CGZ1HTE/Px8otEoVVVVzJs3j5tvvpkPP/wwKTwTj8epq6tj5cqVSeWZskxnJSIcO3aM/fv3881vfpPRo0fTq1cvBg8eTGlpKaWlpSxdujToROwBZvveORyOTjbgF5pFYKfh5eTksHPnTvLy8ujTp08zw5qantYaJnb9ve99LzAOnucxf/58Nm7cSHV1dRAnTpd1YrzqzZs3EwqFeOCBB5LS6lSVBQsW0L9/f7Zt20YsFgsMJxAYXOPJhkIhnn76aV555RVGjRoVdASmExk3bhwrVqzg+PHjwf1M1yEaGYxnPWPGDIYMGUJlZWVSbrWR086qsQ25SSeMx+NUVVUxffp09u7dy7Fjx5g7dy6NjY1B7n04HKa8vJyNGzcG5dvpimZbsmQJc+bM4aOPPqKmpoYxY8Zw1113ceedd/LVr36V2bNnM3bs2EAGu5PKNL/f4fikcFnHwE2YAJq872g0yh/+8AdmzZpF7969k37g5jE/Uy9/7NixFBQUMGTIkMA4qCoDBgyguLiY48ePBx6tXaYxjubY/fffT2lpKX379m2WgldQUMDo0aP58Y9/nCSn3cmkToAJh8NMmDChWS50TU0NQ4cOpaSkJDD6JtRgOgI7FdF0CpFIhJEjR7JhwwaOHj2alO+eTgYjo9EvHo/Tv39/QqEQRUVFfP/732f16tUsXbo06d5MnDiR1atXc/To0aDjMQOp5ikjGo3y0ksvMWDAAKqrq1m8eDG/+tWveOKJJ1i8eDE//OEPufrqq4Ny7UFel0bocCTTqQa8vZkEJlZqp8z95S9/4eWXX6aioiJpYogpvz0hmltuuYVIJMLKlSsDbzoUCtG9e3d69epFXV1dIK+dz5yqS05ODlOmTGk2E9N4uAMHDuTDDz9MmthiY2YtmrKMRwuwadMmXnjhBd5++21mzZrFjTfeGNRvrm0pvc5+aohEIsETgG0YTQdgZ5OYa82Wm5tLeXk5U6ZMoaGhgYULF3LjjTdSW1sb3DNoCqMYeUw4xpbjb3/7W1Df+++/z2OPPcbkyZMZNmwYw4cP56abbmLRokVB3D01fOVwOJq4bGPgxpiYQTkT4jh06BD9+vVj0qRJSfnB9sSRTPnUpz5Fnz59WL9+fZDiZ5dpTy4xZZscaEgYrlOnTuF5XpDiBwQTZiBhyM+cOUO3bt2S5LOnuRsPNR6P85nPfIZwOExdXR2qytq1a7njjjuYNGkSxcXFLFiwIMmo2fLZeeWpRq++vp5Ro0bRpUuXpDxwe5zBXjLAHDftkJeXR1lZWVDf17/+dX7+858HupqnAFse8yRge+A1NTX06tWL+fPnM3ToUCorK4OOYOrUqaxatYpvfetb5OXlJd0bI6PD4WjiYtZCuSAyNbAmk8F4b5FIhIaGBh599FEqKiooLS1tcz2StjC5zNXV1cydO5cVK1Zw9uxZCgoK2LdvXzDhxsR6jadpDxTu3r2bXbt2MXjw4KT8Z9urXr58OT/4wQ8Cr9LoZsejjR59+vShoKAgMKYDBw5k2rRp/P73v+fAgQO89957SZ2FMdi23qkGz0yPHzx4cFJmSWr+dWqnYu47EAywnj9/Hs/zGDRoEHv27GHdunWMHz8+yCoxbWaXZ2QA2Lp1K/fccw8zZ85k5syZDB8+nO7duyetOWM/URlaWzvG4fjEYk/p/ri3ESNGaDwe1/YQi8VUVbW+vl6PHz+uhYWFOnv2bFVV9Twv7bmp+1vC8zwdMWKEiogWFhYqoCKigObm5mrPnj117969Sed7nqfxeDzQY+/evTps2DDdvn17UK+t45IlS7Rv375aU1MT7GtsbFRV1Wg0qtFoNOmaRYsWaSgU0nfeeSc4PxqN6nPPPadlZWV6ww036IEDB5LKSqevva+urk6HDh2qy5cvT7pP6e6dqS8WizU776mnntJu3brpqVOnVFV14sSJOm/evECHRx99VMvKyrSuri7pfsViMT1z5oyeOXNGe/TooW+88UZQptHblGHLHYvFgv0OxycZYJ2msamdHgNvT4jDeF3xeJy8vLxgEOwLX/hCEBfXNIOB9r625DH541/84hd54403WLVqFZs3b2by5MkUFBRwzTWJFRztFDb7sb5fv35Eo1GWLVsWhEGMt9nY2MiiRYuYMWMGPXr0CHQymSj2QKGdc248ZlNnOBxmxowZLFmyhK1bt1JVVRWkIJqYdiqmgT3Po66ujkOHDgUet52hYoeDDPbUd/VnYQIMGjSIeDwezHSdN28eTz75JDU1NXiex9tvv83UqVODeuwxiWXLlrFs2TJqa2uDPH2T4aP+gHBdXV1SXN7M/DT3zeFwJNPpMfBMVwq085HNyoB1dXUUFxdTUlLSrCNQK4yQaRglFotRWFhIeXk5Tz31FBUVFYwfP57y8nImTZpEYWFhEEIwhtLEe00n4XkePXv25MUXXwQIpswDPPPMM6xZs4ZZs2Y1W7bWTNoxYQeT+ldaWoqq8uqrrzZbqKuiooLvfOc7/PSnP01ajrUl7Cn6p06dori4OGlQ2BhIY+wbGxubdX52p9u1a1dCoRBr1qwB4NZbb6W0tJQHHniA1atXs2rVKqZOnRoM3sbj8aTwkwmRGN3tiUSnT59m27ZtzTpm89eeHORwOBJ0ugHP1AO3syWMp9a1a1dOnTqVtMSrHec1fzM14OFwmKlTp/L++++zffv2pHIikQhHjhwJBimhyau1V+XLyclh7ty5HD58mLfeeis479e//jUPPfQQTz75JOXl5YFRMoOgxus03q7pKMaPH09BQUHafPZIJMLQoUPZvn07zz77bNIYgP1YBU3G2zwtdO3aldra2sCA2obfdEyp99x43qaOG264gdGjRydlzMyfP58XXniBiooK+vfvz7Bhw4LjoVCI3NxcYrEYgwYNYtCgQeTn51NVVRUMGgOcPHmSBQsW8MgjjwRPAqmTt9TNxHQ4mtHmIKaI9AWeAT4FeMAvVPUxEekB/Aa4FtgDfFlVT3SkcCaEYk83z8nJYeXKlYwZMwZo8ryNB/vHP/6RI0eO8O1vf7vN8mOxGOPHj0dV2b59O9dff31gLPLy8jh27Bi7d+9m9OjRQV3+PUnypqdOncrSpUu5++67ue+++9iwYQNLlixh0qRJzJo1K6jPGEL7pQy2nvF4nOLiYh5//HEqKiqSjJgxrMXFxc3KMzLZ2N9LSkoYPnx4UhgoXZgpNQMl3fGqqiq6dOkCJDq7L33pSwDU1tYyZcoUioqKgg7CzrgZPnw4ANOnT+eRRx5h9+7dFBQUAPDyyy9zyy238NhjjzXTza1A6HC0TCa/jhjwn1V1MDAW+I6IXA88CPxZVQcCf/a/OxwOh6OzSDey2doG/D8Sb6LfAZT5+8qAHW1dO3LkyIxHXe1MDpMNceLECe3du7eWlpbqO++8o6dOndJnn31W58yZo0OHDtXy8nItKSnRd999N+N6jhw5otdee61WV1fr+fPng/1PPPGE9u7dW3ft2qWqiSwYG5NJoqp67tw59TxPp02bpiKi3bt31/vvv1/37duXsRy2znY2S2pmSywW0/Xr1+u5c+c0Ho8nydEaO3bs0DNnziSVZdfVHvlSM0PMd/se2efY9R08eFCnT5+uIqKRSER79uypL730UrvkcDg+adBCFopoO2a5ici1wJtAObBPVYusYydUtTjNNcFLjfv16zdy7960r3ZrkdT3Pq5Zs4bZs2fzwQcfcNVVV3Hy5EmKi4vp3bs3d911F/feey9FRUVtlJrMiRMnKCwsTFq/2rxUoaioqNkKh/Z3O9siFosF0+9LSkqS3jfZGqrN38lpf7bDEeadn63NwMwEEwNvTxmmTvutRfa9SJ3ynm62qMmwOX/+fDBA2q1btyArJjW85HA4QETWq+qoZvszNeAi0gV4A3hYVV8UkZOZGHCbUaNG6bp16zKqz+5l7JiqkXfTpk2cO3eO3NxcSkpKuO6664CmlxlkYpjSGTE7u8Oe2ZhuYDT1JcV2ve15uXIq58+fD+LD8Xg8KW0xnZyZ6GrSG+0BYHtRrkwMp31P0tVrv+2nJWNu7mV9fT35+flJndzFdkoOx5VKSwY8I3dHRCLA74BnVfVFf/cRESlT1UMiUgbUdJy4ydPCoenHbQYsy8vLCYVCSWuB22/lyQTTIRgDZoyuMUL2y40hOVfaNtD2Wt6mzEgkkrEHbutnFsAyetvG0Cw9a9L/MjW8Rnb7jfRGTlXNuAwjn52KaHeyqamS6TpTc8zcF5OlYu6Zw+HInDbdHUn84v4vsE1V/7d1aBlgUixmkYiNdygmHc0s7mSvZW2/DNcYNjuskQnm1V7GgJkFn1K9bmP8GhsbaWxsTJqMY9dlG8L2GG8gyUjbf01oxpSf+lLhTDEZKKkrH2Z6ryA5vGM8+VQ5bE/bzmYxdRljbfbbr2dzOBzto80QiohMAN4CNpNIIwT4AbAG+C3QD9gH3KGqtW2UdYbE4OeVxNXAsUstRAdzpel0pekDTqdsoCP1+Q+qek3qznYNYl4sIrIuXRwnm3E6Xf5cafqA0ykb6Ax93IiRw+FwZCnOgDscDkeW0tkG/BedXF9n4HS6/LnS9AGnUzbwsevTqTFwh8PhcHQcLoTicDgcWUqnGXARuVVEdojILhHJyoWvRGSPiGwWkb+KyDp/Xw8RWS4iH/h/W52NeqkRkcUiUiMiW6x9aXWQBP/mt9kmERlx6SRvmRZ0WigiB/y2+quI3GYd+6++TjtEZPKlkbplRKSviLwuIttEZKuI3Ofvz9p2akWnbG6nfBF5T0Q2+jr9d3//dSKyxm+n34hIrr8/z/++yz9+7UULkW6BlI7egBDwIdAfyAU2Atd3Rt0drMce4OqUff8TeND//CDwPy61nG3oUAGMALa0pQNwG/AnQEisRLnmUsvfDp0WAg+kOfd6//8vD7jO/78MXWodUmQsA0b4n7sCO325s7adWtEpm9tJgC7+5wiJuTFjScyPudPf/wQwx/98L/CE//lO4DcXK0NneeBjgF2qultVG4HngNs7qe6Pm9uBp/3PTwNTL6EsbaKqbwKpE65a0uF24BlN8C5Q5C+bcFnRgk4tcTvwnKo2qOrfgF0k/j8vG1T1kKpu8D+fAbYBvcnidmpFp5bIhnZSVT3rf434mwI3Ay/4+1PbybTfC8AkkTSLLLWDzjLgvYGPrO/7ab3xLlcUeFVE1ktilUWAUlU9BIl/UqDnJZPuwmlJh2xvt+/6IYXFVmgrq3TyH7OHk/Duroh2StEJsridRCQkIn8lsRbUchJPCidVNeafYssd6OQfPwWUXEz9nWXA0/Uy2Zj+cpOqjgCmkHixRcWlFuhjJpvb7efA3wHDgEPAj/39WaOTJFYA/R3wn1T1dGunptmXLTpldTupalxVhwF9SDwhDE53mv+3w3XqLAO+H+hrfe8DHOykujsMVT3o/60Bfk+iwY6Yx1X5GFZl7CRa0iFr201Vj/g/Lg94kqbH76zQSVpZAdQ/nnXtlE6nbG8ng6qeBFaSiIEXiYhZ2c6WO9DJP96dzEN/aeksA74WGOiPzuaSCOAv66S6OwQRKRSRruYzcAuwhU5YlbETaEmHZcDdfpbDWOCUeYS/3EmJAU8j0VaQ0OlOPyPgOmAg8F5ny9cafly0PSuAXvbt1JJOWd5O14hIkf/5KuAfSMT2Xwem+6eltpNpv+nAa+qPaF4wnThiexuJkecPgfmdVW8Hyt+fxKj4RmCr0YFEDOvPwAf+3x6XWtY29Ph3Eo+qURIewT+2pAOJR77H/TbbDIy61PK3Q6clvsyb/B9OmXX+fF+nHcCUSy1/Gn0mkHi03gT81d9uy+Z2akWnbG6nIcBffNm3AP/k7+9PorPZBTwP5Pn78/3vu/zj/S9WBjcT0+FwOLIUNxPT4XA4shRnwB0OhyNLcQbc4XA4shRnwB0OhyNLcQbc4XA4shRnwB0OhyNLcQbc4XA4shRnwB0OhyNL+f9hxv/giE8jRwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "dtype('O')"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plt.title(Y_labels[8])\n",
    "plt.imshow(X_data[8], cmap=plt.cm.gray)\n",
    "plt.show()\n",
    "\n",
    "X_data.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = X_data[:9000]\n",
    "y_train = Y_labels[:9000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(?, 1, 1, 2520)\n",
      "WARNING:tensorflow:Entity <bound method MultiRNNCell.call of <tensorflow.python.ops.rnn_cell_impl.MultiRNNCell object at 0x661914358>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiRNNCell.call of <tensorflow.python.ops.rnn_cell_impl.MultiRNNCell object at 0x661914358>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method MultiRNNCell.call of <tensorflow.python.ops.rnn_cell_impl.MultiRNNCell object at 0x661914358>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiRNNCell.call of <tensorflow.python.ops.rnn_cell_impl.MultiRNNCell object at 0x661914358>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <bound method LSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.LSTMCell object at 0x661186588>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.LSTMCell object at 0x661186588>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method LSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.LSTMCell object at 0x661186588>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.LSTMCell object at 0x661186588>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <bound method LSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.LSTMCell object at 0x666bcbc88>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.LSTMCell object at 0x666bcbc88>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method LSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.LSTMCell object at 0x666bcbc88>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.LSTMCell object at 0x666bcbc88>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <bound method MultiRNNCell.call of <tensorflow.python.ops.rnn_cell_impl.MultiRNNCell object at 0x661914358>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiRNNCell.call of <tensorflow.python.ops.rnn_cell_impl.MultiRNNCell object at 0x661914358>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method MultiRNNCell.call of <tensorflow.python.ops.rnn_cell_impl.MultiRNNCell object at 0x661914358>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiRNNCell.call of <tensorflow.python.ops.rnn_cell_impl.MultiRNNCell object at 0x661914358>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <bound method LSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.LSTMCell object at 0x661186588>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.LSTMCell object at 0x661186588>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method LSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.LSTMCell object at 0x661186588>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.LSTMCell object at 0x661186588>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <bound method LSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.LSTMCell object at 0x666bcbc88>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.LSTMCell object at 0x666bcbc88>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method LSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.LSTMCell object at 0x666bcbc88>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.LSTMCell object at 0x666bcbc88>>: AttributeError: module 'gast' has no attribute 'Num'\n"
     ]
    }
   ],
   "source": [
    "# Model parameters\n",
    "\n",
    "config = tf.ConfigProto(device_count = {'GPU': 0})\n",
    "config.graph_options.rewrite_options.layout_optimizer = 2\n",
    "\n",
    "tf.reset_default_graph()\n",
    "batchSize = 50\n",
    "imgSize = (18, 310)\n",
    "maxTextLen = 32\n",
    "kernel_vals = [3, 3, 3, 5, 5]\n",
    "feature_vals = [1, 310, 630, 1260, 1260, 2520]\n",
    "stride_vals = pool_vals = [(2,2), (2,2), (2,1), (2,1), (2,1)]\n",
    "\n",
    "num_rnn_hiden = 256\n",
    "\n",
    "charList = \"ABCDEFGHIJKLMNOPQRSTUVWXYZ-\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#Input layer\n",
    "Input = tf.placeholder(tf.float32, shape=(None, imgSize[0], imgSize[1]))\n",
    "\n",
    "#CNN\n",
    "\n",
    "cnnIn4d = tf.expand_dims(input=Input, axis=2)\n",
    "\n",
    "kernel0 = tf.Variable(tf.truncated_normal([kernel_vals[0], kernel_vals[0],feature_vals[0], feature_vals[1]], stddev=0.1))\n",
    "kernel1 = tf.Variable(tf.truncated_normal([kernel_vals[1], kernel_vals[1],feature_vals[1], feature_vals[2]], stddev=0.1))\n",
    "kernel2 = tf.Variable(tf.truncated_normal([kernel_vals[2], kernel_vals[2],feature_vals[2], feature_vals[3]], stddev=0.1))\n",
    "kernel3 = tf.Variable(tf.truncated_normal([kernel_vals[3], kernel_vals[3],feature_vals[3], feature_vals[4]], stddev=0.1))\n",
    "kernel4 = tf.Variable(tf.truncated_normal([kernel_vals[4], kernel_vals[4],feature_vals[4], feature_vals[5]], stddev=0.1))\n",
    "\n",
    "#First CNN layer\n",
    "conv0 = tf.nn.conv2d(cnnIn4d, kernel0, padding='SAME',  strides=(1,1,1,1))\n",
    "relu0 = tf.nn.relu(conv0)\n",
    "pool0 = tf.nn.max_pool(relu0, (1, pool_vals[0][0], pool_vals[0][1], 1), \n",
    "                       (1, stride_vals[0][0], stride_vals[0][1], 1), 'SAME')\n",
    "\n",
    "#Second CNN layer\n",
    "conv1 = tf.nn.conv2d(pool0, kernel1, padding='SAME',  strides=(1,1,1,1))\n",
    "relu1 = tf.nn.relu(conv1)\n",
    "pool1 = tf.nn.max_pool(relu1, (1, pool_vals[1][0], pool_vals[1][1], 1), \n",
    "                       (1, stride_vals[1][0], stride_vals[1][1], 1), 'SAME')\n",
    "\n",
    "#Third CNN layer\n",
    "conv2 = tf.nn.conv2d(pool1, kernel2, padding='SAME',  strides=(1,1,1,1))\n",
    "relu2 = tf.nn.relu(conv2)\n",
    "pool2 = tf.nn.max_pool(relu2, (1, pool_vals[2][0], pool_vals[2][1], 1), \n",
    "                       (1, stride_vals[2][0], stride_vals[2][1], 1), 'SAME')\n",
    "\n",
    "#Fourth CNN layer\n",
    "conv3 = tf.nn.conv2d(pool2, kernel3, padding='SAME',  strides=(1,1,1,1))\n",
    "relu3 = tf.nn.relu(conv3)\n",
    "pool3 = tf.nn.max_pool(relu3, (1, pool_vals[3][0], pool_vals[3][1], 1), \n",
    "                       (1, stride_vals[3][0], stride_vals[3][1], 1), 'SAME')\n",
    "\n",
    "#Fifth CNN layer\n",
    "conv4 = tf.nn.conv2d(pool3, kernel4, padding='SAME',  strides=(1,1,1,1))\n",
    "relu4 = tf.nn.relu(conv4)\n",
    "pool4 = tf.nn.max_pool(relu4, (1, pool_vals[4][0], pool_vals[4][1], 1), \n",
    "                       (1, stride_vals[4][0], stride_vals[4][1], 1), 'SAME')\n",
    "print(pool4.shape)\n",
    "\n",
    "\n",
    "#RNN\n",
    "rnnIn3d = tf.squeeze(pool4, axis=[2])\n",
    "\n",
    "cells = [tf.contrib.rnn.LSTMCell(num_units=num_rnn_hiden, state_is_tuple=True) for _ in range(2)] # 2 layers\n",
    "\n",
    "stacked = tf.contrib.rnn.MultiRNNCell(cells, state_is_tuple=True) # stack basic cells\n",
    "\n",
    "# bidirectional RNN\n",
    "\n",
    "((fw, bw), _) = tf.nn.bidirectional_dynamic_rnn(cell_fw=stacked, \n",
    "                                               cell_bw=stacked, inputs=rnnIn3d, dtype=rnnIn3d.dtype)\n",
    "concat = tf.expand_dims(tf.concat([fw, bw], 2), 2)\n",
    "\n",
    "# project output to chars (including blank): BxTx1x2H -> BxTx1xC -> BxTxC\n",
    "kernel = tf.Variable(tf.truncated_normal([1, 1, num_rnn_hiden * 2, len(charList) + 1], stddev=0.1))\n",
    "\n",
    "rnnOut3d = tf.squeeze(tf.nn.atrous_conv2d(value=concat, filters=kernel, rate=1, padding='SAME'), axis=[2])\n",
    "\n",
    "\n",
    "#BTC\n",
    "ctcIn3dTBC = tf.transpose(rnnOut3d, [1, 0, 2])\n",
    "# ground truth text as sparse tensor\n",
    "gtTexts = tf.SparseTensor(tf.placeholder(tf.int64, shape=[None, 2]) , tf.placeholder(tf.int32, [None]), tf.placeholder(tf.int64, [2]))\n",
    "\n",
    "# calc loss for batch\n",
    "seqLen = tf.placeholder(tf.int32, [None])\n",
    "loss = tf.reduce_mean(tf.nn.ctc_loss(labels=gtTexts, inputs=ctcIn3dTBC, sequence_length=seqLen, ctc_merge_repeated=True))\n",
    "\n",
    "# calc loss for each element to compute label probability\n",
    "savedCtcInput = tf.placeholder(tf.float32, shape=[maxTextLen, None, len(charList) + 1])\n",
    "lossPerElement = tf.nn.ctc_loss(labels=gtTexts, inputs=savedCtcInput, sequence_length=seqLen, ctc_merge_repeated=True)\n",
    "\n",
    "decoder = tf.nn.ctc_greedy_decoder(inputs=ctcIn3dTBC, sequence_length=seqLen)\n",
    "\n",
    "\n",
    "#Optimizer\n",
    "learningRate = 0.001\n",
    "optimizer = tf.train.RMSPropOptimizer(learningRate).minimize(loss)\n",
    "\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HIMELIN\n",
      "7\n",
      "8\n",
      "12\n",
      "4\n",
      "11\n",
      "8\n",
      "13\n",
      "ROBIN\n",
      "17\n",
      "14\n",
      "1\n",
      "8\n",
      "13\n",
      "YOANN\n",
      "24\n",
      "14\n",
      "0\n",
      "13\n",
      "13\n",
      "MARTIN\n",
      "12\n",
      "0\n",
      "17\n",
      "19\n",
      "8\n",
      "13\n",
      "CLEMENT\n",
      "2\n",
      "11\n",
      "4\n",
      "12\n",
      "4\n",
      "13\n",
      "19\n",
      "PRISCILLE\n",
      "15\n",
      "17\n",
      "8\n",
      "18\n",
      "2\n",
      "8\n",
      "11\n",
      "11\n",
      "4\n",
      "VALENTIN\n",
      "21\n",
      "0\n",
      "11\n",
      "4\n",
      "13\n",
      "19\n",
      "8\n",
      "13\n",
      "LEO\n",
      "11\n",
      "4\n",
      "14\n",
      "LAURINE\n",
      "11\n",
      "0\n",
      "20\n",
      "17\n",
      "8\n",
      "13\n",
      "4\n",
      "TATIANA-EVA\n",
      "19\n",
      "0\n",
      "19\n",
      "8\n",
      "0\n",
      "13\n",
      "0\n",
      "26\n",
      "4\n",
      "21\n",
      "0\n",
      "JUITETTE\n",
      "9\n",
      "20\n",
      "8\n",
      "19\n",
      "4\n",
      "19\n",
      "19\n",
      "4\n",
      "NOAH\n",
      "13\n",
      "14\n",
      "0\n",
      "7\n",
      "LEANE\n",
      "11\n",
      "4\n",
      "0\n",
      "13\n",
      "4\n",
      "NOAH\n",
      "13\n",
      "14\n",
      "0\n",
      "7\n",
      "ALICE\n",
      "0\n",
      "11\n",
      "8\n",
      "2\n",
      "4\n",
      "ESTELLE\n",
      "4\n",
      "18\n",
      "19\n",
      "4\n",
      "11\n",
      "11\n",
      "4\n",
      "LEO\n",
      "11\n",
      "4\n",
      "14\n",
      "FLAVIE\n",
      "5\n",
      "11\n",
      "0\n",
      "21\n",
      "8\n",
      "4\n",
      "PAULE-ANDREE\n",
      "15\n",
      "0\n",
      "20\n",
      "11\n",
      "4\n",
      "26\n",
      "0\n",
      "13\n",
      "3\n",
      "17\n",
      "4\n",
      "4\n",
      "NAOFEL\n",
      "13\n",
      "0\n",
      "14\n",
      "5\n",
      "4\n",
      "11\n",
      "ENZO\n",
      "4\n",
      "13\n",
      "25\n",
      "14\n",
      "BASTIEM\n",
      "1\n",
      "0\n",
      "18\n",
      "19\n",
      "8\n",
      "4\n",
      "12\n",
      "LAURENCIANE\n",
      "11\n",
      "0\n",
      "20\n",
      "17\n",
      "4\n",
      "13\n",
      "2\n",
      "8\n",
      "0\n",
      "13\n",
      "4\n",
      "H\n",
      "7\n",
      "ARNAUD\n",
      "0\n",
      "17\n",
      "13\n",
      "0\n",
      "20\n",
      "3\n",
      "CLEMENT\n",
      "2\n",
      "11\n",
      "4\n",
      "12\n",
      "4\n",
      "13\n",
      "19\n",
      "LOUIS\n",
      "11\n",
      "14\n",
      "20\n",
      "8\n",
      "18\n",
      "FLORIAN\n",
      "5\n",
      "11\n",
      "14\n",
      "17\n",
      "8\n",
      "0\n",
      "13\n",
      "AYMERIC\n",
      "0\n",
      "24\n",
      "12\n",
      "4\n",
      "17\n",
      "8\n",
      "2\n",
      "AXEL\n",
      "0\n",
      "23\n",
      "4\n",
      "11\n",
      "REMY\n",
      "17\n",
      "4\n",
      "12\n",
      "24\n",
      "CHLOE\n",
      "2\n",
      "7\n",
      "11\n",
      "14\n",
      "4\n",
      "CAMILLE\n",
      "2\n",
      "0\n",
      "12\n",
      "8\n",
      "11\n",
      "11\n",
      "4\n",
      "HUGO\n",
      "7\n",
      "20\n",
      "6\n",
      "14\n",
      "ELVIS\n",
      "4\n",
      "11\n",
      "21\n",
      "8\n",
      "18\n",
      "GABIN\n",
      "6\n",
      "0\n",
      "1\n",
      "8\n",
      "13\n",
      "MAXENCE\n",
      "12\n",
      "0\n",
      "23\n",
      "4\n",
      "13\n",
      "2\n",
      "4\n",
      "CLAIRE\n",
      "2\n",
      "11\n",
      "0\n",
      "8\n",
      "17\n",
      "4\n",
      "VINCENT\n",
      "21\n",
      "8\n",
      "13\n",
      "2\n",
      "4\n",
      "13\n",
      "19\n",
      "FABIEN\n",
      "5\n",
      "0\n",
      "1\n",
      "8\n",
      "4\n",
      "13\n",
      "MELINDA\n",
      "12\n",
      "4\n",
      "11\n",
      "8\n",
      "13\n",
      "3\n",
      "0\n",
      "LAURINE\n",
      "11\n",
      "0\n",
      "20\n",
      "17\n",
      "8\n",
      "13\n",
      "4\n",
      "JULES\n",
      "9\n",
      "20\n",
      "11\n",
      "4\n",
      "18\n",
      "THEO\n",
      "19\n",
      "7\n",
      "4\n",
      "14\n",
      "CLEA\n",
      "2\n",
      "11\n",
      "4\n",
      "0\n",
      "MAXIME\n",
      "12\n",
      "0\n",
      "23\n",
      "8\n",
      "12\n",
      "4\n",
      "JULES\n",
      "9\n",
      "20\n",
      "11\n",
      "4\n",
      "18\n",
      "ELOISE\n",
      "4\n",
      "11\n",
      "14\n",
      "8\n",
      "18\n",
      "4\n",
      "AUDE\n",
      "0\n",
      "20\n",
      "3\n",
      "4\n",
      "ROXANNE\n",
      "17\n",
      "14\n",
      "23\n",
      "0\n",
      "13\n",
      "13\n",
      "4\n"
     ]
    },
    {
     "ename": "UnimplementedError",
     "evalue": "Generic conv implementation does not support grouped convolutions for now.\n\t [[node Conv2D (defined at <ipython-input-248-7e97cd59ffa8>:35) ]]\n\nErrors may have originated from an input operation.\nInput Source operations connected to node Conv2D:\n ExpandDims (defined at <ipython-input-248-7e97cd59ffa8>:26)\t\n truncated_normal (defined at <ipython-input-248-7e97cd59ffa8>:28)\n\nOriginal stack trace for 'Conv2D':\n  File \"/Users/aitor/anaconda3/lib/python3.7/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/Users/aitor/anaconda3/lib/python3.7/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/Users/aitor/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/Users/aitor/anaconda3/lib/python3.7/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/Users/aitor/anaconda3/lib/python3.7/site-packages/ipykernel/kernelapp.py\", line 505, in start\n    self.io_loop.start()\n  File \"/Users/aitor/anaconda3/lib/python3.7/site-packages/tornado/platform/asyncio.py\", line 148, in start\n    self.asyncio_loop.run_forever()\n  File \"/Users/aitor/anaconda3/lib/python3.7/asyncio/base_events.py\", line 539, in run_forever\n    self._run_once()\n  File \"/Users/aitor/anaconda3/lib/python3.7/asyncio/base_events.py\", line 1775, in _run_once\n    handle._run()\n  File \"/Users/aitor/anaconda3/lib/python3.7/asyncio/events.py\", line 88, in _run\n    self._context.run(self._callback, *self._args)\n  File \"/Users/aitor/anaconda3/lib/python3.7/site-packages/tornado/ioloop.py\", line 690, in <lambda>\n    lambda f: self._run_callback(functools.partial(callback, future))\n  File \"/Users/aitor/anaconda3/lib/python3.7/site-packages/tornado/ioloop.py\", line 743, in _run_callback\n    ret = callback()\n  File \"/Users/aitor/anaconda3/lib/python3.7/site-packages/tornado/gen.py\", line 787, in inner\n    self.run()\n  File \"/Users/aitor/anaconda3/lib/python3.7/site-packages/tornado/gen.py\", line 748, in run\n    yielded = self.gen.send(value)\n  File \"/Users/aitor/anaconda3/lib/python3.7/site-packages/ipykernel/kernelbase.py\", line 365, in process_one\n    yield gen.maybe_future(dispatch(*args))\n  File \"/Users/aitor/anaconda3/lib/python3.7/site-packages/tornado/gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"/Users/aitor/anaconda3/lib/python3.7/site-packages/ipykernel/kernelbase.py\", line 272, in dispatch_shell\n    yield gen.maybe_future(handler(stream, idents, msg))\n  File \"/Users/aitor/anaconda3/lib/python3.7/site-packages/tornado/gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"/Users/aitor/anaconda3/lib/python3.7/site-packages/ipykernel/kernelbase.py\", line 542, in execute_request\n    user_expressions, allow_stdin,\n  File \"/Users/aitor/anaconda3/lib/python3.7/site-packages/tornado/gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"/Users/aitor/anaconda3/lib/python3.7/site-packages/ipykernel/ipkernel.py\", line 294, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/Users/aitor/anaconda3/lib/python3.7/site-packages/ipykernel/zmqshell.py\", line 536, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/Users/aitor/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 2854, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"/Users/aitor/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 2880, in _run_cell\n    return runner(coro)\n  File \"/Users/aitor/anaconda3/lib/python3.7/site-packages/IPython/core/async_helpers.py\", line 68, in _pseudo_sync_runner\n    coro.send(None)\n  File \"/Users/aitor/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3057, in run_cell_async\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/Users/aitor/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3248, in run_ast_nodes\n    if (await self.run_code(code, result,  async_=asy)):\n  File \"/Users/aitor/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3325, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-248-7e97cd59ffa8>\", line 35, in <module>\n    conv0 = tf.nn.conv2d(cnnIn4d, kernel0, padding='SAME',  strides=(1,1,1,1))\n  File \"/Users/aitor/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/nn_ops.py\", line 1953, in conv2d\n    name=name)\n  File \"/Users/aitor/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/gen_nn_ops.py\", line 1071, in conv2d\n    data_format=data_format, dilations=dilations, name=name)\n  File \"/Users/aitor/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py\", line 788, in _apply_op_helper\n    op_def=op_def)\n  File \"/Users/aitor/anaconda3/lib/python3.7/site-packages/tensorflow/python/util/deprecation.py\", line 507, in new_func\n    return func(*args, **kwargs)\n  File \"/Users/aitor/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/ops.py\", line 3616, in create_op\n    op_def=op_def)\n  File \"/Users/aitor/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/ops.py\", line 2005, in __init__\n    self._traceback = tf_stack.extract_stack()\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnimplementedError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1355\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1356\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1357\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1340\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1341\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1342\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1428\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1429\u001b[0;31m         run_metadata)\n\u001b[0m\u001b[1;32m   1430\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mUnimplementedError\u001b[0m: Generic conv implementation does not support grouped convolutions for now.\n\t [[{{node Conv2D}}]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mUnimplementedError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-249-d636fca325ea>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m             \u001b[0mX_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprev_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m             \u001b[0msparse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtoSparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m             \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mInput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mX_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgtTexts\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0msparse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseqLen\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mmaxTextLen\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m             \u001b[0mmse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mInput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mX_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgtTexts\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0msparse\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mseqLen\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mmaxTextLen\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"\\tMSE:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    948\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 950\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    951\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    952\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1171\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1172\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1173\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1174\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1175\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1348\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1349\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1350\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1351\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1352\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1368\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1369\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0merror_interpolation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minterpolate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1370\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1371\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1372\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mUnimplementedError\u001b[0m: Generic conv implementation does not support grouped convolutions for now.\n\t [[node Conv2D (defined at <ipython-input-248-7e97cd59ffa8>:35) ]]\n\nErrors may have originated from an input operation.\nInput Source operations connected to node Conv2D:\n ExpandDims (defined at <ipython-input-248-7e97cd59ffa8>:26)\t\n truncated_normal (defined at <ipython-input-248-7e97cd59ffa8>:28)\n\nOriginal stack trace for 'Conv2D':\n  File \"/Users/aitor/anaconda3/lib/python3.7/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/Users/aitor/anaconda3/lib/python3.7/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/Users/aitor/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/Users/aitor/anaconda3/lib/python3.7/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/Users/aitor/anaconda3/lib/python3.7/site-packages/ipykernel/kernelapp.py\", line 505, in start\n    self.io_loop.start()\n  File \"/Users/aitor/anaconda3/lib/python3.7/site-packages/tornado/platform/asyncio.py\", line 148, in start\n    self.asyncio_loop.run_forever()\n  File \"/Users/aitor/anaconda3/lib/python3.7/asyncio/base_events.py\", line 539, in run_forever\n    self._run_once()\n  File \"/Users/aitor/anaconda3/lib/python3.7/asyncio/base_events.py\", line 1775, in _run_once\n    handle._run()\n  File \"/Users/aitor/anaconda3/lib/python3.7/asyncio/events.py\", line 88, in _run\n    self._context.run(self._callback, *self._args)\n  File \"/Users/aitor/anaconda3/lib/python3.7/site-packages/tornado/ioloop.py\", line 690, in <lambda>\n    lambda f: self._run_callback(functools.partial(callback, future))\n  File \"/Users/aitor/anaconda3/lib/python3.7/site-packages/tornado/ioloop.py\", line 743, in _run_callback\n    ret = callback()\n  File \"/Users/aitor/anaconda3/lib/python3.7/site-packages/tornado/gen.py\", line 787, in inner\n    self.run()\n  File \"/Users/aitor/anaconda3/lib/python3.7/site-packages/tornado/gen.py\", line 748, in run\n    yielded = self.gen.send(value)\n  File \"/Users/aitor/anaconda3/lib/python3.7/site-packages/ipykernel/kernelbase.py\", line 365, in process_one\n    yield gen.maybe_future(dispatch(*args))\n  File \"/Users/aitor/anaconda3/lib/python3.7/site-packages/tornado/gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"/Users/aitor/anaconda3/lib/python3.7/site-packages/ipykernel/kernelbase.py\", line 272, in dispatch_shell\n    yield gen.maybe_future(handler(stream, idents, msg))\n  File \"/Users/aitor/anaconda3/lib/python3.7/site-packages/tornado/gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"/Users/aitor/anaconda3/lib/python3.7/site-packages/ipykernel/kernelbase.py\", line 542, in execute_request\n    user_expressions, allow_stdin,\n  File \"/Users/aitor/anaconda3/lib/python3.7/site-packages/tornado/gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"/Users/aitor/anaconda3/lib/python3.7/site-packages/ipykernel/ipkernel.py\", line 294, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/Users/aitor/anaconda3/lib/python3.7/site-packages/ipykernel/zmqshell.py\", line 536, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/Users/aitor/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 2854, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"/Users/aitor/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 2880, in _run_cell\n    return runner(coro)\n  File \"/Users/aitor/anaconda3/lib/python3.7/site-packages/IPython/core/async_helpers.py\", line 68, in _pseudo_sync_runner\n    coro.send(None)\n  File \"/Users/aitor/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3057, in run_cell_async\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/Users/aitor/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3248, in run_ast_nodes\n    if (await self.run_code(code, result,  async_=asy)):\n  File \"/Users/aitor/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3325, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-248-7e97cd59ffa8>\", line 35, in <module>\n    conv0 = tf.nn.conv2d(cnnIn4d, kernel0, padding='SAME',  strides=(1,1,1,1))\n  File \"/Users/aitor/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/nn_ops.py\", line 1953, in conv2d\n    name=name)\n  File \"/Users/aitor/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/gen_nn_ops.py\", line 1071, in conv2d\n    data_format=data_format, dilations=dilations, name=name)\n  File \"/Users/aitor/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py\", line 788, in _apply_op_helper\n    op_def=op_def)\n  File \"/Users/aitor/anaconda3/lib/python3.7/site-packages/tensorflow/python/util/deprecation.py\", line 507, in new_func\n    return func(*args, **kwargs)\n  File \"/Users/aitor/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/ops.py\", line 3616, in create_op\n    op_def=op_def)\n  File \"/Users/aitor/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/ops.py\", line 2005, in __init__\n    self._traceback = tf_stack.extract_stack()\n"
     ]
    }
   ],
   "source": [
    "epoch = 30\n",
    "batch_size = 50\n",
    "prev_batch = 0\n",
    "\n",
    "with  tf.Session(config=config) as sess:\n",
    "    init.run()\n",
    "    for ep in range(epoch):\n",
    "        for i in range(len(x_train) // batch_size):\n",
    "            X_batch, y_batch = next_batch(prev_batch, batch_size)\n",
    "            sparse = toSparse(y_batch)\n",
    "            sess.run([optimizer,loss], feed_dict={Input: X_batch, gtTexts : sparse, seqLen : [maxTextLen] * batch_size })\n",
    "            mse = loss.eval(feed_dict={Input: X_batch, gtTexts : sparse , seqLen : [maxTextLen] * batch_size})\n",
    "            print(ep, \"\\tMSE:\", mse)\n",
    "    \n",
    "        saver.save(sess, \"./my_time_series_model\") # not shown in the book\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
